---
title: "px spread"
author: "k.hayoung"
output:
  html_document: default
---
**????**  

1. ???? Point 4. ?Ϻ? ???????? Ȱ?? ????�� ????: ?ܼ? ???? ?? ?ٸ? measure?? ???? ?????? Ȱ??  
2. ???? Point 1. ?ϴ?��/?ִ?�� ????: Ÿ?缺 ????  
3. ???? Point 3. Algorithm ????  
4. ???? Point 2. ??�� ?𵨿? ?????? ?????? ??��(Time) ????  

```{r, message=FALSE, warning=FALSE, include=FALSE}
# library needed
require(readxl)
require(zoo)
require(lubridate)
require(plyr)
```

```{r preprocessing, message=FALSE, warning=FALSE, include=FALSE}
# set working directory 
knitr::opts_knit$set(root.dir='D:/px spread/')

# load data
dat.day<-read_excel("px_raw.xlsx",sheet="day")
dat.month<-read_excel("px_raw.xlsx",sheet="month")

# as time series data
names(dat.day)[1]<-"Date"
names(dat.month)[1]<-"Date"
dat.day$Date<-as.Date(dat.day$Date,format="%Y%m%d")
dat.month$Date<-as.Date(as.yearmon(dat.month$Date,format="%Y%m"))

## date class manipulation guide
## extract specific components of Date objects
## weekdays(), months(), quarters()
## dat.day$Date+1
## dat.day$Date>as.Date("2000-03-01")
## dat.day$Date-as.Date("2000-03-01") number of days b/w two objects, difftime object

## creating variables from daily data
## dat.week: split each month into 3 parts

# attach week (1/3) variable to daily data
m.count<-table(format(dat.day$Date,"%Y-%m"))
vec<-vector()
for (i in 1:(length(m.count)-1)){
  vec<-append(vec,c(rep(1,10),rep(2,10),rep(3,(m.count-20)[i])))
}
dat.day$week<-append(vec,c(rep(1,10),rep(2,8)))

# attach month variable to daily data
dat.day$day<-day(dat.day$Date)

# attach month variable to daily & monthly data
dat.day$month<-month(dat.day$Date)
dat.month$month<-month(dat.month$Date)

# attach year variable to daily & monthly data
dat.day$year<-year(dat.day$Date)
dat.month$year<-year(dat.month$Date)

## y: px spread

# daily
names(dat.day)[which(names(dat.day)=="MOPJ Naph")]<-"Naph"
dat.day$y.d<-dat.day[,which(names(dat.day)=="PX")]-dat.day[,which(names(dat.day)=="Naph")] # PX column - MOPJ Naph column

# mean
dat.week<-ddply(dat.day,c("year","month","week"),summarize,px.w.mean=mean(PX,na.rm=TRUE))
dat.week<-merge(dat.week,ddply(dat.day,c("year","month","week"),summarize,naph.w.mean=mean(Naph,na.rm=TRUE)),by=c("year","month","week"),all.x=TRUE)
dat.week$y.w.mean<-dat.week$px.w.mean-dat.week$naph.w.mean
  # weekly PX - weekly MOPJ Naph (not same as 'the mean of daily px' when PX & Naph have NA at different time)

dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,px.m.mean=mean(PX,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,naph.m.mean=mean(Naph,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)
dat.month$y.m.mean<-dat.month$px.m.mean-dat.month$naph.m.mean
  # monthly PX - monthly MOPJ Naph (not same as 'the mean of daily px' when PX & Naph have NA at different time)

# trend
#####dat.week$y.w.trend<-
#####dat.month$y.m.trend<-

# median
dat.week<-merge(dat.week,ddply(dat.day,c("year","month","week"),summarize,px.w.median=median(PX,na.rm=TRUE)),by=c("year","month","week"),all.x=TRUE)
dat.week<-merge(dat.week,ddply(dat.day,c("year","month","week"),summarize,naph.w.median=median(Naph,na.rm=TRUE)),by=c("year","month","week"),all.x=TRUE)
dat.week$y.w.median<-dat.week$px.w.median-dat.week$naph.w.median
  # weekly mean of PX - weekly mean of MOPJ Naph (not same as 'the median of daily px' when PX & Naph have NA at different time)

dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,px.m.median=median(PX,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,naph.m.median=median(Naph,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)
dat.month$y.m.median<-dat.month$px.m.median-dat.month$naph.m.median
  # monthly median of PX - monthly median of MOPJ Naph (not same as 'the median of daily px' when PX & Naph have NA at different time)

# weighted mean
#####dat.month$y.m.wmean<-

## x4: naph price fluctuation

# daily
test1<-na.omit(data.frame(dat.day$year,dat.day$month,dat.day$day,dat.day$Naph)) # delete NA row
test1<-test1[order(test1[,1],test1[,2],test1[,3]),] # check whether test1 is ordered by year, month, day since we assume that previous row = previous day @ next step
test1$previous.Naph[2:dim(test1)[1]]<-test1$dat.day.Naph[1:(dim(test1)[1]-1)] # add previous day column
dat.day<-merge(dat.day,test1,by.x=c("year","month","day","Naph"),by.y=c("dat.day.year","dat.day.month","dat.day.day","dat.day.Naph"),all.x=TRUE) # merge previous day next to today
dat.day$x4.d<-dat.day$Naph-dat.day$previous.Naph # subtract today - previous day

# mean  

# already have weekly naph price = naph.w.mean @ dat.week data frame
test2<-na.omit(data.frame(dat.week$year,dat.week$month,dat.week$week,dat.week$naph.w.mean)) # delete NA row
test2<-test2[order(test2[,1],test2[,2],test2[,3]),] # check whether test2 is ordered by year, month, week since we assume that previous row = previous week @ next step
test2$previous.Naph.mean[2:dim(test2)[1]]<-test2$dat.week.naph.w.mean[1:(dim(test2)[1]-1)] # add previous week column
dat.week<-merge(dat.week,test2,by.x=c("year","month","week","naph.w.mean"),by.y=c("dat.week.year","dat.week.month","dat.week.week","dat.week.naph.w.mean"),all.x=TRUE) # merge previous week next to this week
dat.week$x4.w.mean<-dat.week$naph.w.mean-dat.week$previous.Naph.mean # subtract this week - previous week
  # fluctuation of weekly mean of naph price (not same as 'the mean of fluctuation for a week')

# already have monthly naph price = naph.m.mean @ dat.month data frame
test3<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$naph.m.mean)) # delete NA row
test3<-test3[order(test3[,1],test3[,2],test3[,3]),] # check whether test3 is ordered by year, month since we assume that previous row = previous month @ next step
test3$previous.Naph.mean[2:dim(test3)[1]]<-test3$dat.month.naph.m.mean[1:(dim(test3)[1]-1)] # add previous month column
dat.month<-merge(dat.month,test3,by.x=c("year","month","naph.m.mean"),by.y=c("dat.month.year","dat.month.month","dat.month.naph.m.mean"),all.x=TRUE) # merge previous month next to this month
dat.month$x4.m.mean<-dat.month$naph.m.mean-dat.month$previous.Naph.mean # subtract this week - previous week
  # fluctuation of monthly mean of naph price (not same as 'the mean of fluctuation for a month')

# trend

#####dat.week$x4.w.trend<-
#####dat.month$x4.m.trend<-

# median

# already have weekly naph price = naph.w.median @ dat.week data frame
test4<-na.omit(data.frame(dat.week$year,dat.week$month,dat.week$week,dat.week$naph.w.median)) # delete NA row
test4<-test4[order(test4[,1],test4[,2],test4[,3]),] # check whether test2 is ordered by year, month, week since we assume that previous row = previous week @ next step
test4$previous.Naph.median[2:dim(test4)[1]]<-test4$dat.week.naph.w.median[1:(dim(test4)[1]-1)] # add previous week column
dat.week<-merge(dat.week,test4,by.x=c("year","month","week","naph.w.median"),by.y=c("dat.week.year","dat.week.month","dat.week.week","dat.week.naph.w.median"),all.x=TRUE) # merge previous week next to this week
dat.week$x4.w.median<-dat.week$naph.w.median-dat.week$previous.Naph.median # subtract this week - previous week
  # fluctuation of weekly median of naph price (not same as 'the median of fluctuation for a week')

# already have monthly naph price = naph.m.median @ dat.month data frame
test5<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$naph.m.median)) # delete NA row
test5<-test5[order(test5[,1],test5[,2],test5[,3]),] # check whether test5 is ordered by year, month since we assume that previous row = previous month @ next step
test5$previous.Naph.median[2:dim(test5)[1]]<-test5$dat.month.naph.m.median[1:(dim(test5)[1]-1)] # add previous month column
dat.month<-merge(dat.month,test5,by.x=c("year","month","naph.m.median"),by.y=c("dat.month.year","dat.month.month","dat.month.naph.m.median"),all.x=TRUE) # merge previous month next to this month
dat.month$x4.m.median<-dat.month$naph.m.median-dat.month$previous.Naph.median # subtract this month - previous month
  # fluctuation of monthly median of naph price (not same as 'the median of fluctuation for a month')

# weighted mean
#####dat.month$x4.m.wmean<-

## x5: pta price fluctuation
  
# daily
names(dat.day)[which(names(dat.day)=="PTA USD")]<-"PTAUSD"
test6<-na.omit(data.frame(dat.day$year,dat.day$month,dat.day$day,dat.day$PTAUSD)) # delete NA row
test6<-test6[order(test6[,1],test6[,2],test6[,3]),] # check whether test6 is ordered by year, month, day since we assume that previous row = previous day @ next step
test6$previous.PTAUSD[2:dim(test6)[1]]<-test6$dat.day.PTAUSD[1:(dim(test6)[1]-1)] # add previous day

dat.day<-merge(dat.day,test6,by.x=c("year","month","day","PTAUSD"),by.y=c("dat.day.year","dat.day.month","dat.day.day","dat.day.PTAUSD"),all.x=TRUE) # merge previous day next to today
dat.day$x5.d<-dat.day$PTAUSD-dat.day$previous.PTAUSD # subtract today - previous day

# mean  

# start with adding weekly PTAUSD = pta.w.mean @ dat.week data frame
dat.week<-merge(dat.week,ddply(dat.day,c("year","month","week"),summarize,pta.w.mean=mean(PTAUSD,na.rm=TRUE)),by=c("year","month","week"),all.x=TRUE)  
test7<-na.omit(data.frame(dat.week$year,dat.week$month,dat.week$week,dat.week$pta.w.mean)) # delete NA row
test7<-test7[order(test7[,1],test7[,2],test7[,3]),] # check whether test7 is ordered by year, month, week since we assume that previous row = previous week @ next step
test7$previous.PTAUSD.mean[2:dim(test7)[1]]<-test7$dat.week.pta.w.mean[1:(dim(test7)[1]-1)] # add previous week column
dat.week<-merge(dat.week,test7,by.x=c("year","month","week","pta.w.mean"),by.y=c("dat.week.year","dat.week.month","dat.week.week","dat.week.pta.w.mean"),all.x=TRUE) # merge previous week column next to this week's PTAUSD
dat.week$x5.w.mean<-dat.week$pta.w.mean-dat.week$previous.PTAUSD.mean # subtract this week - previous week
  # fluctuation of weekly mean of pta price (not same as 'the mean of fluctuation for a week')

# start with adding monthly PTAUSD = pta.m.mean @ dat.month data frame
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,pta.m.mean=mean(PTAUSD,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)  
test8<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$pta.m.mean)) # delete NA row
test8<-test8[order(test8[,1],test8[,2],test8[,3]),] # check whether test8 is ordered by year, month, week since we assume that previous row = previous week @ next step
test8$previous.PTAUSD.mean[2:dim(test8)[1]]<-test8$dat.month.pta.m.mean[1:(dim(test8)[1]-1)] # add previous month column
dat.month<-merge(dat.month,test8,by.x=c("year","month","pta.m.mean"),by.y=c("dat.month.year","dat.month.month","dat.month.pta.m.mean"),all.x=TRUE) # merge previous month column next to this month
dat.month$x5.m.mean<-dat.month$pta.m.mean-dat.month$previous.PTAUSD.mean # subtract this month - previous month
  # fluctuation of monthly mean of pta price (not same as 'the mean of fluctuation for a month')

# trend
#####dat.week$x5.w.trend<-
#####dat.month$x5.m.trend<-

# median

# start with adding weekly PTAUSD = pta.w.median @ dat.week data frame
dat.week<-merge(dat.week,ddply(dat.day,c("year","month","week"),summarize,pta.w.median=median(PTAUSD,na.rm=TRUE)),by=c("year","month","week"),all.x=TRUE)  
test9<-na.omit(data.frame(dat.week$year,dat.week$month,dat.week$week,dat.week$pta.w.median)) # delete NA row
test9<-test9[order(test9[,1],test9[,2],test9[,3]),] # check whether test9 is ordered by year, month, week since we assume that previous row = previous week @ next step
test9$previous.PTAUSD.median[2:dim(test9)[1]]<-test9$dat.week.pta.w.median[1:(dim(test9)[1]-1)] # add previous week column
dat.week<-merge(dat.week,test9,by.x=c("year","month","week","pta.w.median"),by.y=c("dat.week.year","dat.week.month","dat.week.week","dat.week.pta.w.median"),all.x=TRUE) # merge previous week column next to this week's PTAUSD
dat.week$x5.w.median<-dat.week$pta.w.median-dat.week$previous.PTAUSD.median # subtract this week - previous week
  # fluctuation of weekly median of pta price (not same as 'the median of fluctuation for a week')

# start with adding monthly PTAUSD = pta.m.median @ dat.month data frame
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,pta.m.median=median(PTAUSD,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)  
test10<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$pta.m.median)) # delete NA row
test10<-test10[order(test10[,1],test10[,2],test10[,3]),] # check whether test10 is ordered by year, month, week since we assume that previous row = previous week @ next step
test10$previous.PTAUSD.median[2:dim(test10)[1]]<-test10$dat.month.pta.m.median[1:(dim(test10)[1]-1)] # add previous month column
dat.month<-merge(dat.month,test10,by.x=c("year","month","pta.m.median"),by.y=c("dat.month.year","dat.month.month","dat.month.pta.m.median"),all.x=TRUE) # merge previous month column next to this month
dat.month$x5.m.median<-dat.month$pta.m.median-dat.month$previous.PTAUSD.median # subtract this month - previous month
  # fluctuation of monthly median of pta price (not same as 'the median of fluctuation for a month')

# weighted mean
#####dat.month$x5.m.wmean<-

## x6: pta future-price fluctuation

# daily
names(dat.day)[which(names(dat.day)=="PTA Futrue Price_Avg_RMB")]<-"PTAFuture"
names(dat.day)[which(names(dat.day)=="RMB PTA")]<-"RMBPTA"
test11<-na.omit(data.frame(dat.day$year,dat.day$month,dat.day$day,dat.day$PTAFuture-dat.day$RMBPTA)) # delete NA row
test11<-test11[order(test11[,1],test11[,2],test11[,3]),] # check whether test11 is ordered by year, month, day since we assume that previous row = previous day @ next step
names(test11)[4]<-"PTAdiff"
test11$previous.PTAdiff[2:dim(test11)[1]]<-test11$PTAdiff[1:(dim(test11)[1]-1)] # add previous day column
dat.day<-merge(dat.day,test11,by.x=c("year","month","day"),by.y=c("dat.day.year","dat.day.month","dat.day.day"),all.x=TRUE) # merge diff & previous day columns next to today's PTAFuture, RMBPTA
dat.day$x6.d<-dat.day$PTAdiff-dat.day$previous.PTAdiff # subtract today - previous day
  # fluctuation of daily difference of PTAfuture & RMBPTA

# mean  

# start with adding weekly PTAFuture & RMBPTA = ptafuture.w.mean & ptarmb.w.mean @ dat.week data frame
dat.week<-merge(dat.week,ddply(dat.day,c("year","month","week"),summarize,ptafuture.w.mean=mean(PTAFuture,na.rm=TRUE)),by=c("year","month","week"),all.x=TRUE)  
dat.week<-merge(dat.week,ddply(dat.day,c("year","month","week"),summarize,ptarmb.w.mean=mean(RMBPTA,na.rm=TRUE)),by=c("year","month","week"),all.x=TRUE)  
# add ptafuture.w.mean-ptarmb.w.mean = PTAdiff.mean @ data.week
test12<-na.omit(data.frame(dat.week$year,dat.week$month,dat.week$week,dat.week$ptafuture.w.mean-dat.week$ptarmb.w.mean)) # delete NA row
names(test12)[4]<-"PTAdiff.mean"
test12<-test12[order(test12[,1],test12[,2],test12[,3]),] # check whether test12 is ordered by year, month, week since we assume that previous row = previous week @ next step
test12$previous.PTAdiff.mean[2:dim(test12)[1]]<-test12$PTAdiff.mean[1:(dim(test12)[1]-1)] # add previous week column
dat.week<-merge(dat.week,test12,by.x=c("year","month","week"),by.y=c("dat.week.year","dat.week.month","dat.week.week"),all.x=TRUE) # merge diff & previous week columns next to this week's PTAFuture, RMBPTA
dat.week$x6.w.mean<-dat.week$PTAdiff.mean-dat.week$previous.PTAdiff.mean # subtract this week - previous week
  # fluctuation of (weekly mean of pta future - weekly mean of pta rmb) (not same as the fluctuation of '7 days' mean of (pta future - pta rmb)')

# start with adding monthly PTAFuture & RMBPTA = ptafuture.w.mean & ptarmb.w.mean @ dat.month data frame
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,ptafuture.m.mean=mean(PTAFuture,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)  
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,ptarmb.m.mean=mean(RMBPTA,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)  
# add ptafuture.m.mean-ptarmb.m.mean = PTAdiff.mean @ data.month
test13<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$ptafuture.m.mean-dat.month$ptarmb.m.mean)) # delete NA row
names(test13)[3]<-"PTAdiff.mean"
test13<-test13[order(test13[,1],test13[,2],test13[,3]),] # check whether test13 is ordered by year, month since we assume that previous row = previous month @ next step
test13$previous.PTAdiff.mean[2:dim(test13)[1]]<-test13$PTAdiff[1:(dim(test13)[1]-1)] # add previous month column
dat.month<-merge(dat.month,test13,by.x=c("year","month"),by.y=c("dat.month.year","dat.month.month"),all.x=TRUE) # merge diff & previous month column next to this month's PTAFuture, RMBPTA
dat.month$x6.m.mean<-dat.month$PTAdiff.mean-dat.month$previous.PTAdiff.mean # subtract this month - previous month
  # fluctuation of (monthly mean of pta future - monthly mean of pta rmb) (not same as the fluctuation of '30 days' mean of (pta future - pta rmb)')

# trend
#####dat.week$x6.w.trend<-
#####dat.month$x6.m.trend<-

# median

# start with adding weekly PTAFuture & RMBPTA = ptafuture.w.median & ptarmb.w.median @ dat.week data frame
dat.week<-merge(dat.week,ddply(dat.day,c("year","month","week"),summarize,ptafuture.w.median=median(PTAFuture,na.rm=TRUE)),by=c("year","month","week"),all.x=TRUE)  
dat.week<-merge(dat.week,ddply(dat.day,c("year","month","week"),summarize,ptarmb.w.median=median(RMBPTA,na.rm=TRUE)),by=c("year","month","week"),all.x=TRUE)  
# add ptafuture.w.median-ptarmb.w.median = PTAdiff.median @ data.week
test14<-na.omit(data.frame(dat.week$year,dat.week$month,dat.week$week,dat.week$ptafuture.w.median-dat.week$ptarmb.w.median)) # delete NA row
names(test14)[4]<-"PTAdiff.median"
test14<-test14[order(test14[,1],test14[,2],test14[,3]),] # check whether test14 is ordered by year, month, week since we assume that previous row = previous week @ next step
test14$previous.PTAdiff.median[2:dim(test14)[1]]<-test14$PTAdiff.median[1:(dim(test14)[1]-1)] # add previous week column
dat.week<-merge(dat.week,test14,by.x=c("year","month","week"),by.y=c("dat.week.year","dat.week.month","dat.week.week"),all.x=TRUE) # merge diff & previous week columns next to this week's PTAFuture, RMBPTA
dat.week$x6.w.median<-dat.week$PTAdiff.median-dat.week$previous.PTAdiff.median # subtract this week - previous week
  # fluctuation of (weekly median of pta future - weekly median of pta rmb) (not same as the fluctuation of '7 days' median of (pta future - pta rmb)')

# start with adding monthly PTAFuture & RMBPTA = ptafuture.w.median & ptarmb.w.median @ dat.month data frame
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,ptafuture.m.median=median(PTAFuture,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)  
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,ptarmb.m.median=median(RMBPTA,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)  
# add ptafuture.m.median-ptarmb.m.median = PTAdiff.median @ data.month
test15<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$ptafuture.m.median-dat.month$ptarmb.m.median)) # delete NA row
names(test15)[3]<-"PTAdiff.median"
test15<-test15[order(test15[,1],test15[,2],test15[,3]),] # check whether test15 is ordered by year, month since we assume that previous row = previous month @ next step
test15$previous.PTAdiff.median[2:dim(test15)[1]]<-test15$PTAdiff[1:(dim(test15)[1]-1)] # add previous month column
dat.month<-merge(dat.month,test15,by.x=c("year","month"),by.y=c("dat.month.year","dat.month.month"),all.x=TRUE) # merge diff & previous month column next to this month's PTAFuture, RMBPTA
dat.month$x6.m.median<-dat.month$PTAdiff.median-dat.month$previous.PTAdiff.median # subtract this month - previous month
  # fluctuation of (monthly median of pta future - monthly median of pta rmb) (not same as the fluctuation of '30 days' median of (pta future - pta rmb)')

# weighted mean
#####dat.month$x6.m.wmean<-

## creating variables from monthly data
## daily data - not available

## x2: px production - demand
test16<-data.frame(dat.month$year,dat.month$month,rowSums(dat.month[,21:25],na.rm=TRUE)-rowSums(dat.month[,30:34],na.rm=TRUE))
names(test16)[3]<-"pro.demand"
dat.month<-merge(dat.month,test16,by.x=c("year","month"),by.y=c("dat.month.year","dat.month.month"),all.x=TRUE)

## x3: 0.67 * pta expansion - px expansion
names(dat.month)[which(names(dat.month)=="PTA-PX Expansion (Asia)")]<-"pta.px.exp"
dat.month$x3.m<-dat.month$pta.px.exp

## order by date
dat.month<-dat.month[order(dat.month[,7]),]
dat.week<-dat.week[order(dat.week[,1],dat.week[,2],dat.week[,3]),]
dat.day<-dat.day[order(dat.day[,6]),]

## summary of variable names
## dat.day> y.d, x4.d, x5.d, x6.d
## dat.week> y.w.mean, y.w.trend, y.w.median, y.w.wmean, x4.w.mean, x4.w.trend, x4.w.median, x4.w.wmean, x5.w.mean, x5.w.trend, x5.w.median, x5.w.wmean, x6.w.mean, x6.w.trend, x6.w.median, x6.w.wmean
## dat.month> y.m.mean, y.m.trend, y.m.median, y.m.wmean, x2.m, x3.m, x4.m.mean, x4.m.trend, x4.m.median, x4.m.wmean, x5.m.mean, x5.m.trend, x5.m.median, x5.m.wmean, x6.m.mean, x6.m.trend, x6.m.median, x6.m.wmean
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
# library needed
require(psych)
require(lattice)
require(latticeExtra)
require(astsa)
require(MASS)
require(forecast)
require(corrplot)
require(car)
require(tseries)
require(ts)
```

**1. ???? Point 4. ?Ϻ? ???????? Ȱ?? ????�� ????: ?ܼ? ???? ?? ?ٸ? measure?? ???? ?????? Ȱ??**  

x4-trend  


```{r, echo=FALSE, message=FALSE, warning=FALSE}
xyplot(x4.d~Date,data=dat.day,type="b",main="x4, 2016.9-10",subset=year%in%2016&month%in%c(9,10))
xyplot(x4.d~Date,data=dat.day,type="b",main="x4, 2016.7-8",subset=year%in%2016&month%in%c(7,8))
xyplot(x4.d~Date,data=dat.day,type="b",main="x4, 2016.5-6",subset=year%in%2016&month%in%c(5,6))
```

x5-trend  
nbsp;

```{r, echo=FALSE, message=FALSE, warning=FALSE}
xyplot(x5.d~Date,data=dat.day,type="b",main="x5, 2016.9-10",subset=year%in%2016&month%in%c(9,10))
xyplot(x5.d~Date,data=dat.day,type="b",main="x5, 2016.7-8",subset=year%in%2016&month%in%c(7,8))
xyplot(x5.d~Date,data=dat.day,type="b",main="x5, 2016.5-6",subset=year%in%2016&month%in%c(5,6))
```

x6-trend  
nbsp;

```{r, echo=FALSE, message=FALSE, warning=FALSE}
xyplot(x6.d~Date,data=dat.day,type="b",main="x6, 2016.9-10",subset=year%in%2016&month%in%c(9,10))
xyplot(x6.d~Date,data=dat.day,type="b",main="x6, 2016.7-8",subset=year%in%2016&month%in%c(8,9))
xyplot(x6.d~Date,data=dat.day,type="b",main="x6, 2016.5-6",subset=year%in%2016&month%in%c(6,7))
```

x4-normal test
```{r, echo=FALSE, message=FALSE, warning=FALSE}
shapiro.test(dat.day$x4.d[which(dat.day$year==2016&dat.day$month==10)])
shapiro.test(dat.day$x4.d[which(dat.day$year==2016&dat.day$month==9)])
shapiro.test(dat.day$x4.d[which(dat.day$year==2016&dat.day$month==8)])
shapiro.test(dat.day$x4.d[which(dat.day$year==2016&dat.day$month==7)])
shapiro.test(dat.day$x4.d[which(dat.day$year==2016&dat.day$month==6)])
shapiro.test(dat.day$x4.d[which(dat.day$year==2016&dat.day$month==5)])
```

```{r}

```


x5-normal test
```{r, echo=FALSE, message=FALSE, warning=FALSE}
shapiro.test(dat.day$x5.d[which(dat.day$year==2016&dat.day$month==10)])
shapiro.test(dat.day$x5.d[which(dat.day$year==2016&dat.day$month==9)])
shapiro.test(dat.day$x5.d[which(dat.day$year==2016&dat.day$month==8)])
shapiro.test(dat.day$x5.d[which(dat.day$year==2016&dat.day$month==7)])
shapiro.test(dat.day$x5.d[which(dat.day$year==2016&dat.day$month==6)])
shapiro.test(dat.day$x5.d[which(dat.day$year==2016&dat.day$month==5)])
```

x6-normal test
```{r, echo=FALSE, message=FALSE, warning=FALSE}
shapiro.test(dat.day$x6.d[which(dat.day$year==2016&dat.day$month==10)])
shapiro.test(dat.day$x6.d[which(dat.day$year==2016&dat.day$month==9)])
shapiro.test(dat.day$x6.d[which(dat.day$year==2016&dat.day$month==8)])
shapiro.test(dat.day$x6.d[which(dat.day$year==2016&dat.day$month==7)])
shapiro.test(dat.day$x6.d[which(dat.day$year==2016&dat.day$month==6)])
shapiro.test(dat.day$x6.d[which(dat.day$year==2016&dat.day$month==5)])
par(mfrow=c(1,2))
hist(dat.day$x6.d[which(dat.day$year==2016&dat.day$month==9)])
hist(dat.day$x6.d[which(dat.day$year==2016&dat.day$month==5)])
```


**???? Point 1. ?ϴ?��/?ִ?�� ????: Ÿ?缺 ????**  
2005.01-2016.10


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# daily trend - daily data
xyplot(y.d~Date,data=dat.day,type="b",subset=year%in%c(2005:2016),xlab="month",ylab="daily spread",main="PX spread, daily data, 2005-2016") # plot 2005-2016 data
```

Zoom out each year


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# 2014
dat.y.d<-subset(dat.day,year%in%c(2014:2016),select=c(Date,year,month,y.d)) # subset 2014-2016
# dat.y.d<-dat.y.d[!is.na(dat.y.d[,4]),] # delete NA rows to connect the line
xyplot(y.d~Date,data=dat.y.d,type="b",subset=year%in%2014,xlab="month",ylab="daily spread",main="PX spread, daily data, 2014") # plot 2014 data
xyplot(y.d~Date,data=dat.y.d,type="b",subset=year%in%2015,xlab="month",ylab="daily spread",main="PX spread, daily data, 2015") # plot 2015 data
xyplot(y.d~Date,data=dat.y.d,type="b",subset=year%in%2016,xlab="month",ylab="daily spread",main="PX spread, daily data, 2016") # plot 2016 data
```

**detect seasonality (month, week, day effect)**  
```{r, message=FALSE, warning=FALSE, include=FALSE}
ts1<-subset(dat.day,year%in%c(2005:2016),select=c(Date,month,week,day,y.d))
ts1$qtr<-quarter(ts1$Date)
ts1$wdays<-weekdays(ts1$Date)
ts1<-ts1[which(is.na(ts1$y.d)==0),]
ts1$month<-as.factor(ts1$month)
ts1$qtr<-as.factor(ts1$qtr)
ts1$week<-as.factor(ts1$week)
ts1$wdays<-as.factor(ts1$wdays)
str(ts1)
```

month effect might exist    
```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(aov(ts1$y.d~ts1$month)) # evidence of month of the year effect
bartlett.test(ts1$y.d~ts1$month) # assumption is not met
```

quarter effect might exist  
```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(aov(ts1$y.d~ts1$qtr)) # evidence of quarter of the year effect
bartlett.test(ts1$y.d~ts1$qtr) # assumption is not met
```

week effect does not exist
```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(aov(ts1$y.d~ts1$week)) # no week effect (H1: any one week is different from others)
bartlett.test(ts1$y.d~ts1$week) # ok
```

day effect does not exist
```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(aov(ts1$y.d~ts1$wdays)) # no day effect (H1: any one day is different from others)
bartlett.test(ts1$y.d~ts1$wdays) # ok
```

look further into quarter effect - low at 2nd & 4th quarter
```{r, echo=FALSE, message=FALSE, warning=FALSE}
ts1<-cbind(ts1,model.matrix(~ts1$qtr),model.matrix(~ts1$month))
summary(lm(ts1$y.d~ts1$`ts1$qtr2`+ts1$`ts1$qtr3`+ts1$`ts1$qtr4`))
```

look further into month effect  
```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(lm(ts1$y.d~ts1$`ts1$month2`+ts1$`ts1$month3`+ts1$`ts1$month4`+ts1$`ts1$month5`+ts1$`ts1$month6`+ts1$`ts1$month7`+ts1$`ts1$month8`+ts1$`ts1$month9`+ts1$`ts1$month10`+ts1$`ts1$month11`+ts1$`ts1$month12`))
```

extract seasonal component - lower at 2nd/4th quarter  
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# decompose seasonal component = low at 2nd/4th quater
ts.2005<-na.omit(ts(subset(dat.month,year%in%c(2005:2016),select=c(Date,y.m.mean))$y.m.mean[-c(143,144)],start=c(2005,1),frequency=12))
ts.2005.stl<-stl(ts.2005,s.window="periodic")
plot(ts.2005.stl)
```

subtract trend - only seasonality & random effects remains 
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# original data - trend
trend.ts<-rollmean(ts.2005,4)
detrend<-ts.2005-trend.ts
detrend<-data.frame(date=as.vector(time(detrend)),detrend=as.vector(detrend),year=format(as.Date(as.yearmon(time(detrend))),"%Y"))

xyplot(detrend~date,data=detrend,type="b",panel=function(x,y,...){
        panel.abline(v=detrend$date[seq(from=1,to=144,by=12)],lty="dotted",col="grey")
        panel.xyplot( x,y,...)},main="PX spread after detrend, monthly mean, 2005-2016") # plot whole data

xyplot(detrend~date,data=detrend,type="b",panel=function(x,y,...){        panel.abline(v=detrend$date[seq(from=3,to=139,by=3)],lty="dotted",col="grey")
        panel.xyplot( x,y,...)},subset=year%in%c(2012:2016),main="PX spread after detrend, monthly mean, 2012-2016") # plot recent data
```

(same procedure to recent years 2012-2016)
```{r, message=FALSE, warning=FALSE, include=FALSE}
## recent years - similar result
ts2<-subset(dat.day,year%in%c(2012:2016),select=c(Date,month,week,day,y.d))
ts2$qtr<-quarter(ts2$Date)
ts2$wdays<-weekdays(ts2$Date)
ts2<-ts2[which(is.na(ts2$y.d)==0),]
ts2$month<-as.factor(ts2$month)
ts2$qtr<-as.factor(ts2$qtr)
ts2$week<-as.factor(ts2$week)
ts2$wdays<-as.factor(ts2$wdays)
str(ts2)
```

test month effect - yes
```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(aov(ts2$y.d~ts2$month)) # evidence of month of the year effect
bartlett.test(ts2$y.d~ts2$month) # assumption is not met
```

test quarter effect - yes
```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(aov(ts2$y.d~ts2$qtr)) # evidence of quarter of the year effect
bartlett.test(ts2$y.d~ts2$qtr) # assumption is not met
```

test week effect - no
```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(aov(ts2$y.d~ts2$week)) # no week effect (H1: any one week is different from others)
bartlett.test(ts2$y.d~ts2$week) # ok
```

test day effect - no
```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(aov(ts2$y.d~ts2$wdays)) # no day effect (H1: any one day is different from others)
bartlett.test(ts2$y.d~ts2$wdays) # ok
```

look further into quarter effect - low at 2nd & 4th quarter
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# look further into quarter & monthly effect
ts2<-cbind(ts2,model.matrix(~ts2$qtr),model.matrix(~ts2$month))
summary(lm(ts2$y.d~ts2$`ts2$qtr2`+ts2$`ts2$qtr3`+ts2$`ts2$qtr4`))
```

look further into month effect
```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(lm(ts2$y.d~ts2$`ts2$month2`+ts2$`ts2$month3`+ts2$`ts2$month4`+ts2$`ts2$month5`+ts2$`ts2$month6`+ts2$`ts2$month7`+ts2$`ts2$month8`+ts2$`ts2$month9`+ts2$`ts2$month10`+ts2$`ts2$month11`+ts2$`ts2$month12`))
```

**basic EDA**


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# monthly trend - montly mean through whole range (2005~2016)
dat.y.m.mean<-subset(dat.month,year%in%c(2005:2016),select=c(Date,year,month,y.m.mean)) # subset 2005-2016
dat.y.m.mean<-dat.y.m.mean[!is.na(dat.y.m.mean[,4]),] # delete NA rows to connect the line
xyplot(y.m.mean~Date,data=dat.y.m.mean,type="b",panel=function(x,y,...){
        panel.abline(v=dat.y.m.mean$Date[seq(from=1,to=144,by=12)],lty="dotted",col="grey")
        panel.xyplot( x,y,...)},main="PX spread, monthly mean, 2005-2016") # plot whole data

## irregular seasonaltiy
## underlying pattern seems to be different over years

# histogram, boxplot, qqplot & basic statistics
layout(matrix(c(1,2,3,3), 2, 2, byrow = FALSE))
hist(dat.y.m.mean$y.m.mean,
     main = "Histogram of monthly PX Spread",
     xlab = "PX Spread")
qqnorm(dat.y.m.mean$y.m.mean);qqline(dat.y.m.mean$y.m.mean)
boxplot(dat.y.m.mean$y.m.mean,
        main = "Boxplot of monthly PX Spread",
        ylab = "PX Spread",
        col = "grey")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
describe(dat.y.m.mean$y.m.mean)[,-c(1)]
```

*[set up original model for comparison]*
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# set up for regression: all variables till lag 6

# y.m.mean
test100<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$y.m.mean)) # delete NA row
test100<-test100[order(test100[,1],test100[,2],test100[,3]),] # check whether test100 is ordered by year, month since we assume that previous row = previous month @ next step
test100$previous.y.m.mean[2:dim(test100)[1]]<-test100$dat.month.y.m.mean[1:(dim(test100)[1]-1)] # add previous month column
test100$twoago.y.m.mean[3:dim(test100)[1]]<-test100$dat.month.y.m.mean[1:(dim(test100)[1]-2)] # add 2 months ago column
test100$threeago.y.m.mean[4:dim(test100)[1]]<-test100$dat.month.y.m.mean[1:(dim(test100)[1]-3)] # add 3 months ago column
test100$fourago.y.m.mean[5:dim(test100)[1]]<-test100$dat.month.y.m.mean[1:(dim(test100)[1]-4)] # add 4 months ago column
test100$fiveago.y.m.mean[6:dim(test100)[1]]<-test100$dat.month.y.m.mean[1:(dim(test100)[1]-5)] # add 5 months ago column
test100$sixago.y.m.mean[7:dim(test100)[1]]<-test100$dat.month.y.m.mean[1:(dim(test100)[1]-6)] # add 6 months ago column
dat.month<-merge(dat.month,test100,by.x=c("year","month","y.m.mean"),by.y=c("dat.month.year","dat.month.month","dat.month.y.m.mean"),all.x=TRUE) # merge next to this month

# px.m.mean
test101<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$px.m.mean)) # delete NA row
test101<-test101[order(test101[,1],test101[,2],test101[,3]),] # check whether test101 is ordered by year, month since we assume that previous row = previous month @ next step
test101$previous.px.m.mean[2:dim(test101)[1]]<-test101$dat.month.px.m.mean[1:(dim(test101)[1]-1)] # add previous month column
test101$twoago.px.m.mean[3:dim(test101)[1]]<-test101$dat.month.px.m.mean[1:(dim(test101)[1]-2)] # add 2 months ago column
test101$threeago.px.m.mean[4:dim(test101)[1]]<-test101$dat.month.px.m.mean[1:(dim(test101)[1]-3)] # add 3 months ago column
test101$fourago.px.m.mean[5:dim(test101)[1]]<-test101$dat.month.px.m.mean[1:(dim(test101)[1]-4)] # add 4 months ago column
test101$fiveago.px.m.mean[6:dim(test101)[1]]<-test101$dat.month.px.m.mean[1:(dim(test101)[1]-5)] # add 5 months ago column
test101$sixago.px.m.mean[7:dim(test101)[1]]<-test101$dat.month.px.m.mean[1:(dim(test101)[1]-6)] # add 6 months ago column
dat.month<-merge(dat.month,test101,by.x=c("year","month","px.m.mean"),by.y=c("dat.month.year","dat.month.month","dat.month.px.m.mean"),all.x=TRUE) # merge next to this month

# naph.m.mean
test102<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$naph.m.mean)) # delete NA row
test102<-test102[order(test102[,1],test102[,2],test102[,3]),] # check whether test102 is ordered by year, month since we assume that previous row = previous month @ next step
test102$previous.naph.m.mean[2:dim(test102)[1]]<-test102$dat.month.naph.m.mean[1:(dim(test102)[1]-1)] # add previous month column
test102$twoago.naph.m.mean[3:dim(test102)[1]]<-test102$dat.month.naph.m.mean[1:(dim(test102)[1]-2)] # add 2 months ago column
test102$threeago.naph.m.mean[4:dim(test102)[1]]<-test102$dat.month.naph.m.mean[1:(dim(test102)[1]-3)] # add 3 months ago column
test102$fourago.naph.m.mean[5:dim(test102)[1]]<-test102$dat.month.naph.m.mean[1:(dim(test102)[1]-4)] # add 4 months ago column
test102$fiveago.naph.m.mean[6:dim(test102)[1]]<-test102$dat.month.naph.m.mean[1:(dim(test102)[1]-5)] # add 5 months ago column
test102$sixago.naph.m.mean[7:dim(test102)[1]]<-test102$dat.month.naph.m.mean[1:(dim(test102)[1]-6)] # add 6 months ago column
dat.month<-merge(dat.month,test102,by.x=c("year","month","naph.m.mean"),by.y=c("dat.month.year","dat.month.month","dat.month.naph.m.mean"),all.x=TRUE) # merge next to this month

# pro.demand
test103<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$pro.demand)) # delete NA row
test103<-test103[order(test103[,1],test103[,2],test103[,3]),] # check whether test103 is ordered by year, month since we assume that previous row = previous month @ next step
test103$previous.pro.demand[2:dim(test103)[1]]<-test103$dat.month.pro.demand[1:(dim(test103)[1]-1)] # add previous month column
test103$twoago.pro.demand[3:dim(test103)[1]]<-test103$dat.month.pro.demand[1:(dim(test103)[1]-2)] # add 2 months ago column
test103$threeago.pro.demand[4:dim(test103)[1]]<-test103$dat.month.pro.demand[1:(dim(test103)[1]-3)] # add 3 months ago column
test103$fourago.pro.demand[5:dim(test103)[1]]<-test103$dat.month.pro.demand[1:(dim(test103)[1]-4)] # add 4 months ago column
test103$fiveago.pro.demand[6:dim(test103)[1]]<-test103$dat.month.pro.demand[1:(dim(test103)[1]-5)] # add 5 months ago column
test103$sixago.pro.demand[7:dim(test103)[1]]<-test103$dat.month.pro.demand[1:(dim(test103)[1]-6)] # add 6 months ago column
dat.month<-merge(dat.month,test103,by.x=c("year","month","pro.demand"),by.y=c("dat.month.year","dat.month.month","dat.month.pro.demand"),all.x=TRUE) # merge next to this month

# x3
test104<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$x3.m)) # delete NA row
test104<-test104[order(test104[,1],test104[,2],test104[,3]),] # check whether test104 is ordered by year, month since we assume that previous row = previous month @ next step
test104$previous.x3.m[2:dim(test104)[1]]<-test104$dat.month.x3.m[1:(dim(test104)[1]-1)] # add previous month column
test104$twoago.x3.m[3:dim(test104)[1]]<-test104$dat.month.x3.m[1:(dim(test104)[1]-2)] # add 2 months ago column
test104$threeago.x3.m[4:dim(test104)[1]]<-test104$dat.month.x3.m[1:(dim(test104)[1]-3)] # add 3 months ago column
test104$fourago.x3.m[5:dim(test104)[1]]<-test104$dat.month.x3.m[1:(dim(test104)[1]-4)] # add 4 months ago column
test104$fiveago.x3.m[6:dim(test104)[1]]<-test104$dat.month.x3.m[1:(dim(test104)[1]-5)] # add 5 months ago column
test104$sixago.x3.m[7:dim(test104)[1]]<-test104$dat.month.x3.m[1:(dim(test104)[1]-6)] # add 6 months ago column
dat.month<-merge(dat.month,test104,by.x=c("year","month","x3.m"),by.y=c("dat.month.year","dat.month.month","dat.month.x3.m"),all.x=TRUE) # merge next to this month

# x4.m.mean
test105<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$x4.m.mean)) # delete NA row
test105<-test105[order(test105[,1],test105[,2],test105[,3]),] # check whether test105 is ordered by year, month since we assume that previous row = previous month @ next step
test105$previous.x4.m.mean[2:dim(test105)[1]]<-test105$dat.month.x4.m.mean[1:(dim(test105)[1]-1)] # add previous month column
test105$twoago.x4.m.mean[3:dim(test105)[1]]<-test105$dat.month.x4.m.mean[1:(dim(test105)[1]-2)] # add 2 months ago column
test105$threeago.x4.m.mean[4:dim(test105)[1]]<-test105$dat.month.x4.m.mean[1:(dim(test105)[1]-3)] # add 3 months ago column
test105$fourago.x4.m.mean[5:dim(test105)[1]]<-test105$dat.month.x4.m.mean[1:(dim(test105)[1]-4)] # add 4 months ago column
test105$fiveago.x4.m.mean[6:dim(test105)[1]]<-test105$dat.month.x4.m.mean[1:(dim(test105)[1]-5)] # add 5 months ago column
test105$sixago.x4.m.mean[7:dim(test105)[1]]<-test105$dat.month.x4.m.mean[1:(dim(test105)[1]-6)] # add 6 months ago column
dat.month<-merge(dat.month,test105,by.x=c("year","month","x4.m.mean"),by.y=c("dat.month.year","dat.month.month","dat.month.x4.m.mean"),all.x=TRUE) # merge next to this month

# x5.m.mean
test106<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$x5.m.mean)) # delete NA row
test106<-test106[order(test106[,1],test106[,2],test106[,3]),] # check whether test106 is ordered by year, month since we assume that previous row = previous month @ next step
test106$previous.x5.m.mean[2:dim(test106)[1]]<-test106$dat.month.x5.m.mean[1:(dim(test106)[1]-1)] # add previous month column
test106$twoago.x5.m.mean[3:dim(test106)[1]]<-test106$dat.month.x5.m.mean[1:(dim(test106)[1]-2)] # add 2 months ago column
test106$threeago.x5.m.mean[4:dim(test106)[1]]<-test106$dat.month.x5.m.mean[1:(dim(test106)[1]-3)] # add 3 months ago column
test106$fourago.x5.m.mean[5:dim(test106)[1]]<-test106$dat.month.x5.m.mean[1:(dim(test106)[1]-4)] # add 4 months ago column
test106$fiveago.x5.m.mean[6:dim(test106)[1]]<-test106$dat.month.x5.m.mean[1:(dim(test106)[1]-5)] # add 5 months ago column
test106$sixago.x5.m.mean[7:dim(test106)[1]]<-test106$dat.month.x5.m.mean[1:(dim(test106)[1]-6)] # add 6 months ago column
dat.month<-merge(dat.month,test106,by.x=c("year","month","x5.m.mean"),by.y=c("dat.month.year","dat.month.month","dat.month.x5.m.mean"),all.x=TRUE) # merge next to this month

### x6.m.mean
test107<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$x6.m.mean)) # delete NA row
test107<-test107[order(test107[,1],test107[,2],test107[,3]),] # check whether test107 is ordered by year, month since we assume that previous row = previous month @ next step
test107$previous.x6.m.mean[2:dim(test107)[1]]<-test107$dat.month.x6.m.mean[1:(dim(test107)[1]-1)] # add previous month column
test107$twoago.x6.m.mean[3:dim(test107)[1]]<-test107$dat.month.x6.m.mean[1:(dim(test107)[1]-2)] # add 2 months ago column
test107$threeago.x6.m.mean[4:dim(test107)[1]]<-test107$dat.month.x6.m.mean[1:(dim(test107)[1]-3)] # add 3 months ago column
test107$fourago.x6.m.mean[5:dim(test107)[1]]<-test107$dat.month.x6.m.mean[1:(dim(test107)[1]-4)] # add 4 months ago column
test107$fiveago.x6.m.mean[6:dim(test107)[1]]<-test107$dat.month.x6.m.mean[1:(dim(test107)[1]-5)] # add 5 months ago column
test107$sixago.x6.m.mean[7:dim(test107)[1]]<-test107$dat.month.x6.m.mean[1:(dim(test107)[1]-6)] # add 6 months ago column
dat.month<-merge(dat.month,test107,by.x=c("year","month","x6.m.mean"),by.y=c("dat.month.year","dat.month.month","dat.month.x6.m.mean"),all.x=TRUE) # merge next to this month
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# y = y.m.mean, x1 = y.m.mean (????), x2 = pro.demand, x3 = x3.m (????+??????), x4 = x4.m.mean , x5 = x5.m.mean (????), x6 = x6.m.mean (????, 2015 ???? NA)

dat.original<-subset(dat.month,year%in%c(2014:2016),select=c(Date,year,month,y.m.mean,previous.y.m.mean,pro.demand,previous.x3.m,twoago.x3.m,x4.m.mean,previous.x5.m.mean,previous.x6.m.mean))
dat.original<-dat.original[1:34,] # delete incomplete row at the end 2016.11-12
dat.original$twosum.x3.m<-dat.original$previous.x3.m+dat.original$twoago.x3.m # sum expansion
dat.original$previous.x6.m.mean[1:12]<-mean(dat.original$previous.x6.m.mean[13:34])  # 2015 future data as mean
lm_original<-lm(y.m.mean~previous.y.m.mean+pro.demand+twosum.x3.m+x4.m.mean+previous.x5.m.mean+previous.x6.m.mean,data=dat.original)
summary(lm_original) # original model

lm_original.df<-data.frame(dat.original$y.m.mean,dat.original$previous.y.m.mean,dat.original$pro.demand,dat.original$twosum.x3.m,dat.original$x4.m.mean+dat.original$previous.x5.m.mean+dat.original$previous.x6.m.mean)
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
###### original model - for comparison
predict.original<-data.frame(predict=NA,real=NA,lw.95ci=NA,up.95ci=NA)
for (i in 1:10){
lm<-lm(y.m.mean~previous.y.m.mean+pro.demand+twosum.x3.m+x4.m.mean+previous.x5.m.mean+previous.x6.m.mean,data=dat.original[1:(23+i),])
print(lm$coefficients[1:7])
predict.original[i,1]<-predict(lm,dat.original[24+i,],interval="prediction",level=0.95)[,1]
predict.original[i,2]<-dat.original[24+i,4]
predict.original[i,3]<-predict(lm,dat.original[24+i,],interval="prediction",level=0.95)[,2]
predict.original[i,4]<-predict(lm,dat.original[24+i,],interval="prediction",level=0.95)[,3]
  }
cverror.original<-sqrt(sum((predict.original[,1]-predict.original[,2])^2)/10)
```

mean of MSE from 2016.01-2016.10
```{r, echo=FALSE, message=FALSE, warning=FALSE}
predict.original
cverror.original
```


**???? Point3. Algorithm ????**  
decomposion method  
mean of MSE from 2016.01-2016.10
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# validate the model
prediction.decomp.ts<-data.frame(predict=NA,real=NA,lw.95ci=NA,up.95ci=NA)
for (i in 1:10){
  ts.2005.decomp<-ts(ts.2005[1:(131+i)],start=c(2005,1),frequency=12)
  ts.decomp<-stl(ts.2005.decomp,s.window="periodic")
  prediction.decomp.ts[i,1]<-forecast(ts.decomp)$mean[1]
  prediction.decomp.ts[i,2]<-ts.2005[132+i]
  prediction.decomp.ts[i,3]<-forecast(ts.decomp)$lower[1,2]
  prediction.decomp.ts[i,4]<-forecast(ts.decomp)$upper[1,2]}  

cverror.decomp<-sqrt(sum((prediction.decomp.ts[,1]-prediction.decomp.ts[,2])^2)/10)
cverror.decomp
```

log transformation to stabilize the variance
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# take transformation to stabilize variance
ts.2005<-na.omit(ts(subset(dat.month,year%in%c(2005:2016),select=c(Date,y.m.mean))$y.m.mean[-c(143,144)],start=c(2005,1),frequency=12))
boxcox(ts.2005~1)
# 95% CI includes 0
# take log transformation to make explanation easier
```

acf/pacf of log time series


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# log time series
par(mfrow=c(1,2))
acf(ts.2005[1:133])
pacf(ts.2005[1:133])
```

auto.arima function will search the most appropriate model based on lowest AIC  
take non-stationary data as an input and determine the order of differencing using a unit-root test
```{r,echo=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
ts.2005.sarima<-auto.arima(log(ts.2005)) # SARIMA(1,0,1)(2,0,0)[12]
ts.2005.sarima
```

auto.arima did not take any difference - since it depends on kpss test
```{r,echo=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
kpss.test(log(ts.2005)) # stationary
```

examine the residuals

```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot(ts.2005.sarima$residuals)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
tsdiag(ts.2005.sarima)
```

validate the model
```{r, message=FALSE, warning=FALSE, include=FALSE}
sarima.real<-data.frame(predict=NA,real=NA,lw.95ci=NA,up.95ci=NA,o.predict=predict.original[,1],o.lw.95ci=predict.original[,3],o.up.95ci=predict.original[,4])

for (i in 1:10){
ts.2005.sarima<-sarima(log(ts.2005)[1:(131+i)],p=1,d=0,q=1,P=2,D=0,Q=0,S=12)
sarima.real[i,1]<-exp(sarima.for(log(ts.2005)[1:(131+i)],n.ahead=1,p=1,d=0,q=1,P=2,D=0,Q=0,S=12)$pred)
sarima.real[i,2]<-ts.2005[132+i]
sarima.real[i,3]<-exp(sarima.for(log(ts.2005)[1:(131+i)],n.ahead=1,p=1,d=0,q=1,P=2,D=0,Q=0,S=12)$pred-qnorm(0.975)*sarima.for(log(ts.2005)[1:(131+i)],n.ahead=1,p=1,d=0,q=1,P=2,D=0,Q=0,S=12)$se)
sarima.real[i,4]<-exp(sarima.for(log(ts.2005)[1:(131+i)],n.ahead=1,p=1,d=0,q=1,P=2,D=0,Q=0,S=12)$pred+qnorm(0.975)*sarima.for(log(ts.2005)[1:(131+i)],n.ahead=1,p=1,d=0,q=1,P=2,D=0,Q=0,S=12)$se)}
cverror.sarima<-sqrt(sum((sarima.real[,1]-sarima.real[,2])^2)/10)
sarima.real
cverror.sarima
```

visualize it - compare it with the original model: worse result  


```{r, echo=FALSE, message=FALSE, warning=FALSE}
matplot(sarima.real,type=c("p","b","p","p","p","p","p"),pch=c(8,20,18,18,8,18,18),col=c("red","black","red","red","grey","grey","grey"),ylim=c(220,880),xlab="2016.month")
legend(x=7.5,y=880,c("real value","arma prediction","arma pi","linear prediction","linear pi"),col=c("black","red","red","grey","grey"),pch=c(20,8,18,8,18))
text(x=4,y=850,"cv error of original regression=22.21, sarima=23.49")
text(x=4,y=800,"one step prediction using previous data")
```

px/naph price seperately


```{r, echo=FALSE, message=FALSE, warning=FALSE}
xyplot(PX~Date,data=dat.day,type="b",main="PX/Naph seperately",subset=year%in%c(2005:2016),key=list(columns=2, 
        text=list(lab=c("Naph","PX")),
        points=list(pch=c(1,NA), col="black"),
        points=list(pch=c(NA,1), col="blue"),
        lines=list(lty=c(1,0), col="black"), 
        lines=list(lty=c(0,1), col="blue")))+as.layer(
xyplot(Naph~Date,data=dat.day,type="b",col="black"),y.same=FALSE)
```

zoom out recent years


```{r, echo=FALSE, message=FALSE, warning=FALSE}
xyplot(PX~Date,data=dat.day,subset=year%in%c(2011:2016),type="b",main="PX/Naph seperately",key=list(columns=2, 
        text=list(lab=c("Naph","PX")),
        points=list(pch=c(1,NA), col="black"),
        points=list(pch=c(NA,1), col="blue"),
        lines=list(lty=c(1,0), col="black"), 
        lines=list(lty=c(0,1), col="blue")))+as.layer(
xyplot(Naph~Date,data=dat.day,subset=year%in%c(2011:2016),type="b",col="black"),y.same=FALSE)
```

apply additive decomposition method  
mean of MSE from 2016.01-2016.10

```{r, echo=FALSE, message=FALSE, warning=FALSE}
px.2005<-na.omit(ts(subset(dat.month,year%in%c(2005:2016),select=c(Date,px.m.mean))$px.m.mean[-c(143,144)],start=c(2005,1),frequency=12))
naph.2005<-na.omit(ts(subset(dat.month,year%in%c(2005:2016),select=c(Date,naph.m.mean))$naph.m.mean[-c(143,144)],start=c(2005,1),frequency=12))
# px.2005.stl<-stl(px.2005,s.window="periodic")
# naph.2005.stl<-stl(naph.2005,s.window="periodic")

# validate the model
prediction.decomp.px<-data.frame(predict=NA,real=NA,lw.95ci=NA,up.95ci=NA)
for (i in 1:10){
  px.2005.decomp<-ts(px.2005[1:(131+i)],start=c(2005,1),frequency=12)
  px.decomp<-stl(px.2005.decomp,s.window="periodic")
  prediction.decomp.px[i,1]<-forecast(px.decomp)$mean[1]
  prediction.decomp.px[i,2]<-px.2005[132+i]
  prediction.decomp.px[i,3]<-forecast(px.decomp)$lower[1,2]
  prediction.decomp.px[i,4]<-forecast(px.decomp)$upper[1,2]}  

prediction.decomp.naph<-data.frame(predict=NA,real=NA,lw.95ci=NA,up.95ci=NA)
for (i in 1:10){
  naph.2005.decomp<-ts(naph.2005[1:(131+i)],start=c(2005,1),frequency=12)
  naph.decomp<-stl(naph.2005.decomp,s.window="periodic")
  prediction.decomp.naph[i,1]<-forecast(naph.decomp)$mean[1]
  prediction.decomp.naph[i,2]<-naph.2005[132+i]
  prediction.decomp.naph[i,3]<-forecast(naph.decomp)$lower[1,2]
  prediction.decomp.naph[i,4]<-forecast(naph.decomp)$upper[1,2]}

cverror.decomp<-sqrt(sum(((prediction.decomp.px[,1]-prediction.decomp.naph[,1])-(prediction.decomp.px[,2]-prediction.decomp.naph[,2]))^2)/10)
cverror.decomp
```

apply auto.arima


```{r, echo=FALSE, message=FALSE, warning=FALSE}
boxcox(px.2005~1)
```
```{r, message=FALSE, warning=FALSE, include=FALSE}
px.2005.sarima<-auto.arima(log(px.2005))
px.2005.sarima
# auto.arima selects ARIMA(1,1,2)
```

auto.arima takes 1 difference - stationary ok on diff(logx) data
```{r,echo=FALSE}
kpss.test(diff(log(px.2005)))
```

examine the residuals


```{r,echo=FALSE}
tsdiag(px.2005.sarima)
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
# validate the model
prediction.px.sarima<-data.frame(predict=NA,real=NA,lw.95ci=NA,up.95ci=NA)

for (i in 1:10){
px.2005.sarima<-sarima(log(px.2005)[1:(131+i)],p=1,d=1,q=2,P=0,D=0,Q=0,S=0)
prediction.px.sarima[i,1]<-exp(sarima.for(log(px.2005)[1:(131+i)],n.ahead=1,p=1,d=1,q=2,P=0,D=0,Q=0,S=0)$pred)
prediction.px.sarima[i,2]<-px.2005[132+i]
prediction.px.sarima[i,3]<-exp(sarima.for(log(px.2005)[1:(131+i)],n.ahead=1,p=1,d=1,q=2,P=0,D=0,Q=0,S=0)$pred-qnorm(0.975)*sarima.for(log(px.2005)[1:(131+i)],n.ahead=1,p=1,d=1,q=2,P=0,D=0,Q=0,S=0)$se)
prediction.px.sarima[i,4]<-exp(sarima.for(log(px.2005)[1:(131+i)],n.ahead=1,p=1,d=1,q=2,P=0,D=0,Q=0,S=0)$pred+qnorm(0.975)*sarima.for(log(px.2005)[1:(131+i)],n.ahead=1,p=1,d=1,q=2,P=0,D=0,Q=0,S=0)$se)}
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
boxcox(naph.2005~1)
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
naph.2005.sarima<-auto.arima(log(naph.2005))
naph.2005.sarima
# ARIMA(0,1,1)
```

auto.arima takes 1 difference - stationary ok on diff(logx) data
```{r, echo=FALSE, message=FALSE, warning=FALSE}
kpss.test(diff(log(naph.2005)))
```

examine the residuals


```{r, echo=FALSE, message=FALSE, warning=FALSE}
tsdiag(naph.2005.sarima)
```

mean of MSE from 2016.01-2016.10
```{r, message=FALSE, warning=FALSE, include=FALSE}
# validate
prediction.naph.sarima<-data.frame(predict=NA,real=NA,lw.95ci=NA,up.95ci=NA)

for (i in 1:10){
naph.2005.sarima<-sarima(log(naph.2005)[1:(131+i)],p=1,d=1,q=2,P=0,D=0,Q=0,S=0)
prediction.naph.sarima[i,1]<-exp(sarima.for(log(naph.2005)[1:(131+i)],n.ahead=1,p=1,d=1,q=2,P=0,D=0,Q=0,S=0)$pred)
prediction.naph.sarima[i,2]<-naph.2005[132+i]
prediction.naph.sarima[i,3]<-exp(sarima.for(log(naph.2005)[1:(131+i)],n.ahead=1,p=1,d=1,q=2,P=0,D=0,Q=0,S=0)$pred-qnorm(0.975)*sarima.for(log(naph.2005)[1:(131+i)],n.ahead=1,p=1,d=1,q=2,P=0,D=0,Q=0,S=0)$se)
prediction.naph.sarima[i,4]<-exp(sarima.for(log(naph.2005)[1:(131+i)],n.ahead=1,p=1,d=1,q=2,P=0,D=0,Q=0,S=0)$pred+qnorm(0.975)*sarima.for(log(naph.2005)[1:(131+i)],n.ahead=1,p=1,d=1,q=2,P=0,D=0,Q=0,S=0)$se)}

cverror.sarima.sep<-sqrt(sum(((prediction.px.sarima[,1]-prediction.naph.sarima[,1])-(prediction.px.sarima[,2]-prediction.naph.sarima[,2]))^2)/10)
cverror.sarima.sep
```

**???? Point2. ??�� ?𵨿? ?????? ?????? ??��(Time) ????**

X2
```{r x2 setting, message=FALSE, warning=FALSE, include=FALSE}
dat.x2<-subset(dat.month,year%in%c(2014:2016),select=c(Date,year,month,pro.demand,y.m.mean,px.m.mean,naph.m.mean)) # subset 2014-2016
dat.x2<-dat.x2[!is.na(dat.x2[,4]+dat.x2[,5]),] # delete NA rows
```

visualize both series in one graph


```{r x2 time plots, echo=FALSE, message=FALSE, warning=FALSE}
# x2 time series plot (with y for comparison)
xyplot(pro.demand~Date,data=dat.x2,type="b",main="PX production-demand - Y",key=list(columns=2, 
        text=list(lab=c("px spread","production-demand")),
        points=list(pch=c(NA,1), col="blue"),
        lines=list(lty=c(1,0), col="grey"), 
        lines=list(lty=c(0,1), col="blue")))+as.layer(
xyplot(y.m.mean~Date,data=dat.x2,type="l",col="grey"),y.same=FALSE)
```

histogram, qq plot, box plot, basic statistics
```{r x2 plots, echo=FALSE, message=FALSE, warning=FALSE}
# histogram, boxplot, qqplot 
layout(matrix(c(1,2,3,3), 2, 2, byrow = FALSE))
hist(dat.x2$pro.demand,
     main = "2014-2016 Histogram of PX Production-Demand",
     xlab = "PX P-D")
qqnorm(dat.x2$pro.demand);qqline(dat.x2$pro.demand)
boxplot(dat.x2$pro.demand,
        main = "2014-2016 Boxplot of PX Production-demand",
        ylab = "PX P-D",
        col = "grey")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# basic statistics
describe(dat.x2$pro.demand)[,-c(1)]
```

original regression - lag 0 (i=1)  
  

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# scatter plot
# y?? same row = lag0: 2.20?Ͽ? 3??�� ?????? ??��?? 3???? spread?? ????
# ??��: march row = 3?? ????�� ?????? ?????? ??Ȯ??
# previous row of x2 (lag1): 1.20?Ͽ? 2??�� ?????? ??��?? 3???? spread?? ???? 
# ??, aromatic ???????? 2??�� ?????? ??�� 2?? spread ?? ?ƴ϶? 3?? spread???? ????�� ??ĥ ?? ?ִ?

## previous model: same row ?????? ???⸸ ????

# plot
xyplot(y.m.mean~pro.demand,data=dat.x2)+as.layer(
xyplot(y.m.mean~pro.demand,data=dat.x2,type="smooth",col="grey",lty="dotted"))
```
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# correlation
correlation<-function(x,y){
data.frame(method=c("pearson","kendall","spearman"),correlation=c(cor(x,y,method="pearson"),cor(x,y,method="kendall"),cor(x,y,method="spearman")))}
correlation(dat.x2$pro.demand,dat.x2$y.m.mean)
```

extending lags


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# increase lag, in order to find the best period to be included

par(mfrow=c(3,1))

x2.cor.pearson<-vector()
for (i in 1:8){
  x2.cor.pearson[i]<-cor(dat.x2$y.m.mean[i:dim(dat.x2)[1]],dat.x2$pro.demand[1:(dim(dat.x2)[1]-(i-1))],method="pearson")}
plot(x2.cor.pearson,type="b")
abline(h=0,lty="dotted",col="grey")

x2.cor.kendall<-vector()
for (i in 1:8){
  x2.cor.kendall[i]<-cor(dat.x2$y.m.mean[i:dim(dat.x2)[1]],dat.x2$pro.demand[1:(dim(dat.x2)[1]-(i-1))],method="kendall")}
plot(x2.cor.kendall,type="b")
abline(h=0,lty="dotted",col="grey")

x2.cor.spearman<-vector()
for (i in 1:8){
  x2.cor.spearman[i]<-cor(dat.x2$y.m.mean[i:dim(dat.x2)[1]],dat.x2$pro.demand[1:(dim(dat.x2)[1]-(i-1))],method="spearman")}
plot(x2.cor.spearman,type="b")
abline(h=0,lty="dotted",col="grey")

# ??�� ?????? Ȱ?? ???Ŀ? ?ٰ??ϸ?, 
# ??�� ???? ?????ʹ? 'Jan-14 = 1??�� ?????? ??'?̸? ?? ???? 1?? spread?? ????�� ??ĥ ???̶??? ?? 
# ?׷??? ?׷??��? ???? ??�� ?࿡???? correlation ?????? 0?? ?????? 2,3,4 ?? ?????? ???? ??Ÿ?? (lag 1,2,3)
# ?ǹ?: 4???? spread?? ?????Ѵٰ? ?ϸ?, 4???? ????�� ?????? ?????? 1,2,3???? ????�� ?????? ???? ?? 4?? spread?? ????�� ??ġ?? ??��?? ??Ÿ?? 
# ????: 1???? ??ǥ?? 2?? ??????�� Jan-14???? labeling ??��???? ?ұ??ϰ?, ??�� row?? ?ΰ? Ȱ????�� ???ɼ?
# ?׷??? ?ϴ????? ?? ???????? ?????? ?? ??�� ????�� ??ġ?? ?κп? ???? Biz. Ȯ??

# correlation becomes larger again after 1 year, might be because of sesonality of x2
```

X3
```{r x3 setting, message=FALSE, warning=FALSE, include=FALSE}
dat.x3<-subset(dat.month,year%in%c(2014:2016),select=c(Date,year,month,x3.m,y.m.mean,px.m.mean,naph.m.mean)) # subset 2014-2016
dat.x3<-dat.x3[!is.na(dat.x3[,4]+dat.x3[,5]),] # delete NA rows
```

visualize both series in one graph


```{r x3 time plots, echo=FALSE, message=FALSE, warning=FALSE}
# x3 time series plot (with y for comparison)
xyplot(x3.m~Date,data=dat.x3,type="b",main="PTA-PX expansion - Y",key=list(columns=2, 
        text=list(lab=c("px spread","pta expansion-px expansion")),
        points=list(pch=c(NA,1), col="blue"),
        lines=list(lty=c(1,0), col="grey"), 
        lines=list(lty=c(0,1), col="blue")))+as.layer(
xyplot(y.m.mean~Date,data=dat.x3,type="l",col="grey"),y.same=FALSE)
```

histogram, qq plot, box plot, basic statistics
```{r x3 plots, echo=FALSE, message=FALSE, warning=FALSE}
# histogram, boxplot, qqplot 
layout(matrix(c(1,2,3,3), 2, 2, byrow = FALSE))
hist(dat.x3$x3.m,
     main = "2014-2016 Histogram of PTA-PX expansion",
     xlab = "PX P-D")
qqnorm(dat.x3$x3.m);qqline(dat.x3$x3.m)
boxplot(dat.x3$x3.m,
        main = "2014-2016 Boxplot of PTA-PX expansion",
        ylab = "PX P-D",
        col = "grey")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# basic statistics
describe(dat.x3$x3.m)[,-c(1)]
```

original regression - lag 1,2 (i=2,3)  
lag 1
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# scatter plot
# y?? same row = lag 1,2: 1,2???? ???????? 3???? spread?? ????

## previous model: ????, ?????? ?????? ???⸸ ????

# plot - effect of 1 lag row (i=2)
xyplot(y.m.mean[2:dim(dat.x3)[1]]~x3.m[1:(dim(dat.x3)[1]-1)],data=dat.x3)+as.layer(
xyplot(y.m.mean[2:dim(dat.x3)[1]]~x3.m[1:(dim(dat.x3)[1]-1)],data=dat.x3,type="smooth",col="grey",lty="dotted"))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# correlation - effect of 1 lag row (i=2)
correlation<-function(x,y){
data.frame(method=c("pearson","kendall","spearman"),correlation=c(cor(x,y,method="pearson"),cor(x,y,method="kendall"),cor(x,y,method="spearman")))}
correlation(dat.x3$x3.m[1:(dim(dat.x3)[1]-1)],dat.x3$y.m.mean[2:dim(dat.x3)[1]])
```

lag 2
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# plot - effect of 2 lag row (i=3)
xyplot(y.m.mean[3:dim(dat.x3)[1]]~x3.m[1:(dim(dat.x3)[1]-2)],data=dat.x3)+as.layer(
xyplot(y.m.mean[3:dim(dat.x3)[1]]~x3.m[1:(dim(dat.x3)[1]-2)],data=dat.x3,type="smooth",col="grey",lty="dotted"))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# correlation - effect of 2 lag row (i=3)
correlation<-function(x,y){
data.frame(method=c("pearson","kendall","spearman"),correlation=c(cor(x,y,method="pearson"),cor(x,y,method="kendall"),cor(x,y,method="spearman")))}
correlation(dat.x3$x3.m[1:(dim(dat.x3)[1]-2)],dat.x3$y.m.mean[3:dim(dat.x3)[1]])
```

extending lags


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# increase lag, in order to find the best period to be included

par(mfrow=c(3,1))

x3.cor.pearson<-vector()
for (i in 1:8){
  x3.cor.pearson[i]<-cor(dat.x3$y.m.mean[i:dim(dat.x3)[1]],dat.x3$x3.m[1:(dim(dat.x3)[1]-(i-1))],method="pearson")}
plot(x3.cor.pearson,type="b")
abline(h=0,lty="dotted",col="grey")

x3.cor.kendall<-vector()
for (i in 1:8){
  x3.cor.kendall[i]<-cor(dat.x3$y.m.mean[i:dim(dat.x3)[1]],dat.x3$x3.m[1:(dim(dat.x3)[1]-(i-1))],method="kendall")}
plot(x3.cor.kendall,type="b")
abline(h=0,lty="dotted",col="grey")

x3.cor.spearman<-vector()
for (i in 1:8){
  x3.cor.spearman[i]<-cor(dat.x3$y.m.mean[i:dim(dat.x3)[1]],dat.x3$x3.m[1:(dim(dat.x3)[1]-(i-1))],method="spearman")}
plot(x3.cor.spearman,type="b")
abline(h=0,lty="dotted",col="grey")

# ??��?? ?м??Ͻ? ?????? Ȱ?? ???Ŀ? ?ٰ??ϸ?, 
# ??�� ???? ?????ʹ? 'Jan = 1?? ??????'?̸? ?? ???? 2,3?? spread?? ????�� ??ĥ ???̶??? ?? 
# ?Ʒ? ?׷??��??? i=2,3?? ?ش??ϴµ? 2?? 0?? ?????? 3,4 ?? ?????? ???? ??Ÿ?? (lag 2,3)
# ?ǹ?: 4???? spread?? ?????Ѵٰ? ?ϸ?, 2,3???? ?????????? 1,2???? ???????? ?? 4?? spread?? ????�� ??ġ?? ??��?? ??Ÿ?? 

# i=7???? ��?? ??��??
```

X4
```{r x4 setting, echo=FALSE, message=FALSE, warning=FALSE}
dat.x4<-subset(dat.month,year%in%c(2005:2016),select=c(Date,year,month,x4.m.mean,y.m.mean,px.m.mean,naph.m.mean)) # subset 2005-2016
dat.x4<-dat.x4[!is.na(dat.x4[,4]+dat.x4[,5]),] # delete NA rows
```

visualize both series in one graph


```{r x4 time plots, echo=FALSE, message=FALSE, warning=FALSE}
# x4 time series plot (with y for comparison)
xyplot(x4.m.mean~Date,data=dat.x4,type="b",main="naph fluctuation - Y",key=list(columns=2, 
        text=list(lab=c("px spread","naph fluctuation")),
        points=list(pch=c(NA,1), col="blue"),
        lines=list(lty=c(1,0), col="grey"), 
        lines=list(lty=c(0,1), col="blue")))+as.layer(
xyplot(y.m.mean~Date,data=dat.x4,type="l",col="grey"),y.same=FALSE)
```

histogram, qq plot, box plot, basic statistics
```{r x4 plots, echo=FALSE, message=FALSE, warning=FALSE}
# histogram, boxplot, qqplot 
layout(matrix(c(1,2,3,3), 2, 2, byrow = FALSE))
hist(dat.x4$x4.m.mean,
     main = "2005-2016 Histogram of naph fluctuation",
     xlab = "naph f")
qqnorm(dat.x4$x4.m.mean);qqline(dat.x4$x4.m.mean)
boxplot(dat.x4$x4.m.mean,
        main = "2005-2016 Boxplot of naph fluctuation",
        ylab = "naph f",
        col = "grey")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# basic statistics
describe(dat.x4$x4.m.mean)[,-c(1)]
```

original regression - lag 0 (i=1)


```{r x4 relationship with y, echo=FALSE, message=FALSE, warning=FALSE}
# scatter plot
# y?? same row = lag 0: 3???? naph ??????��?? 3???? spread?? ????
# ??��: march row = 3?? ???��? ?????? ?????? ??Ȯ??

## previous model: same row ?????? ???⸸ ????

# plot
xyplot(y.m.mean~x4.m.mean,data=dat.x4)+as.layer(
xyplot(y.m.mean~x4.m.mean,data=dat.x4,type="smooth",col="grey",lty="dotted"))
```
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# correlation
correlation(dat.x4$x4.m.mean,dat.x4$y.m.mean)
```
extending lags


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# increase lag, in order to find the best period to be included

par(mfrow=c(3,1))

x4.cor.pearson<-vector()
for (i in 1:8){
  x4.cor.pearson[i]<-cor(dat.x4$y.m.mean[i:dim(dat.x4)[1]],dat.x4$x4.m.mean[1:(dim(dat.x4)[1]-(i-1))],method="pearson")}
plot(x4.cor.pearson,type="b")
abline(h=0,lty="dotted",col="grey")

x4.cor.kendall<-vector()
for (i in 1:8){
  x4.cor.kendall[i]<-cor(dat.x4$y.m.mean[i:dim(dat.x4)[1]],dat.x4$x4.m.mean[1:(dim(dat.x4)[1]-(i-1))],method="kendall")}
plot(x4.cor.kendall,type="b")
abline(h=0,lty="dotted",col="grey")

x4.cor.spearman<-vector()
for (i in 1:8){
  x4.cor.spearman[i]<-cor(dat.x4$y.m.mean[i:dim(dat.x4)[1]],dat.x4$x4.m.mean[1:(dim(dat.x4)[1]-(i-1))],method="spearman")}
plot(x4.cor.spearman,type="b")
abline(h=0,lty="dotted",col="grey")

# ??��?? ?м??Ͻ? ?????? Ȱ?? ???Ŀ? ?ٰ??ϸ?, 
# ??�� ???? ?????ʹ? 'Jan = ?????? 1???? naph ????'?̸? ?? ???? 1?? spread?? ????�� ??ĥ ???̶??? ?? 

# ?????? ��?? ???踦 ????? 2008 ?߶??? ?õ??
```

x5
```{r x5 setting, message=FALSE, warning=FALSE, include=FALSE}
dat.x5<-subset(dat.month,year%in%c(2011:2016),select=c(Date,year,month,x5.m.mean,y.m.mean,px.m.mean,naph.m.mean)) # subset 2011-2016
dat.x5<-dat.x5[!is.na(dat.x5[,4]+dat.x5[,5]),] # delete NA rows
```

visualize both series in one graph


```{r x5 time plots, echo=FALSE, message=FALSE, warning=FALSE}
# x5 time series plot (with y for comparison)
xyplot(x5.m.mean~Date,data=dat.x5,type="b",main="PTA fluctuation - Y",key=list(columns=2, 
        text=list(lab=c("px spread","pta fluctuation")),
        points=list(pch=c(NA,1), col="blue"),
        lines=list(lty=c(1,0), col="grey"), 
        lines=list(lty=c(0,1), col="blue")))+as.layer(
xyplot(y.m.mean~Date,data=dat.x5,type="l",col="grey"),y.same=FALSE)
```

histogram, qq plot, box plot, basic statistics
```{r x5 plots, echo=FALSE, message=FALSE, warning=FALSE}
# histogram, boxplot, qqplot 
layout(matrix(c(1,2,3,3), 2, 2, byrow = FALSE))
hist(dat.x5$x5.m.mean,
     main = "2011-2016 Histogram of pta fluctuation",
     xlab = "naph f")
qqnorm(dat.x5$x5.m.mean);qqline(dat.x5$x5.m.mean)
boxplot(dat.x5$x5.m.mean,
        main = "2011-2016 Boxplot of pta fluctuation",
        ylab = "naph f",
        col = "grey")
```
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# basic statistics
describe(dat.x5$x5.m.mean)[,-c(1)]
```

original regression - lag 1 (i=2)


```{r,echo=FALSE}
# scatter plot
# y?? same row = lag 1: 2???? PTA ???? 3???? spread?? ????

## previous model: ???? ?????? ???⸸ ????

# plot
xyplot(y.m.mean[2:dim(dat.x5)[1]]~x5.m.mean[1:(dim(dat.x5)[1]-1)],data=dat.x5)+as.layer(
xyplot(y.m.mean[2:dim(dat.x5)[1]]~x5.m.mean[1:(dim(dat.x5)[1]-1)],data=dat.x5,type="smooth",col="grey",lty="dotted"))
```
```{r,echo=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
# correlation
correlation(dat.x5$x5.m.mean[1:(dim(dat.x5)[1]-1)],dat.x5$y.m.mean[2:dim(dat.x5)[1]])
```

extending lags


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# increase lag, in order to find the best period to be included

par(mfrow=c(3,1))

x5.cor.pearson<-vector()
for (i in 1:8){
  x5.cor.pearson[i]<-cor(dat.x5$y.m.mean[i:dim(dat.x5)[1]],dat.x5$x5.m.mean[1:(dim(dat.x5)[1]-(i-1))],method="pearson")}
plot(x5.cor.pearson,type="b")
abline(h=0,lty="dotted",col="grey")

x5.cor.kendall<-vector()
for (i in 1:8){
  x5.cor.kendall[i]<-cor(dat.x5$y.m.mean[i:dim(dat.x5)[1]],dat.x5$x5.m.mean[1:(dim(dat.x5)[1]-(i-1))],method="kendall")}
plot(x5.cor.kendall,type="b")
abline(h=0,lty="dotted",col="grey")

x5.cor.spearman<-vector()
for (i in 1:8){
  x5.cor.spearman[i]<-cor(dat.x5$y.m.mean[i:dim(dat.x5)[1]],dat.x5$x5.m.mean[1:(dim(dat.x5)[1]-(i-1))],method="spearman")}
plot(x5.cor.spearman,type="b")
abline(h=0,lty="dotted",col="grey")

# ??��?? ?м??Ͻ? ?????? Ȱ?? ???Ŀ? ?ٰ??ϸ?, 
# y?? same row = lag 1: 2???? PTA??��?? 3???? spread?? ????
# ?°? ?????? ?? ??��
# ??, ?Ⱓ�� ?? ?????ص? ?? ?? ???⵵ ??
```

x6
```{r x6 setting, message=FALSE, warning=FALSE, include=FALSE}
dat.x6<-subset(dat.month,year%in%c(2015,2016),select=c(Date,year,month,x6.m.mean,y.m.mean,px.m.mean,naph.m.mean)) # subset 2015-2016
dat.x6<-dat.x6[!is.na(dat.x6[,4]+dat.x6[,5]),] # delete NA rows
```

visualize both series in one graph


```{r x6 time plots, echo=FALSE, message=FALSE, warning=FALSE}
# x6 time series plot (with y for comparison)
xyplot(x6.m.mean~Date,data=dat.x6,type="b",main="PTA future - Y",key=list(columns=2, 
        text=list(lab=c("px spread","pta future-price fluctuation")),
        points=list(pch=c(NA,1), col="blue"),
        lines=list(lty=c(1,0), col="grey"), 
        lines=list(lty=c(0,1), col="blue")))+as.layer(
xyplot(y.m.mean~Date,data=dat.x6,type="l",col="grey"),y.same=FALSE)
```

histogram, qq plot, box plot, basic statistics
```{r x6 plots, echo=FALSE, message=FALSE, warning=FALSE}
# histogram, boxplot, qqplot 
layout(matrix(c(1,2,3,3), 2, 2, byrow = FALSE))
hist(dat.x6$x6.m.mean,
     main = "2016 Histogram of pta future",
     xlab = "pta future")
qqnorm(dat.x6$x6.m.mean);qqline(dat.x6$x6.m.mean)
boxplot(dat.x6$x6.m.mean,
        main = "2016 Boxplot of pta future",
        ylab = "naph future",
        col = "grey")
```
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# basic statistics
describe(dat.x6$x6.m.mean)[,-c(1)]
```

original regression - lag 1 (i=2)


```{r,echo=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
# scatter plot
# y?? same row = lag 1: 2????  ????-???? ???? 3???? spread?? ????

## previous model: ???? ?????? ???⸸ ????

# plot
xyplot(y.m.mean[2:dim(dat.x6)[1]]~x6.m.mean[1:(dim(dat.x6)[1]-1)],data=dat.x6)+as.layer(
xyplot(y.m.mean[2:dim(dat.x6)[1]]~x6.m.mean[1:(dim(dat.x6)[1]-1)],data=dat.x6,type="smooth",col="grey",lty="dotted"))
```
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# correlation
correlation(dat.x6$x6.m.mean[1:(dim(dat.x6)[1]-1)],dat.x6$y.m.mean[2:dim(dat.x6)[1]])
```

extending lags


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# increase lag, in order to find the best period to be included

par(mfrow=c(3,1))

x6.cor.pearson<-vector()
for (i in 1:8){
  x6.cor.pearson[i]<-cor(dat.x6$y.m.mean[i:dim(dat.x6)[1]],dat.x6$x6.m.mean[1:(dim(dat.x6)[1]-(i-1))],method="pearson")}
plot(x6.cor.pearson,type="b")
abline(h=0,lty="dotted",col="grey")

x6.cor.kendall<-vector()
for (i in 1:8){
  x6.cor.kendall[i]<-cor(dat.x6$y.m.mean[i:dim(dat.x6)[1]],dat.x6$x6.m.mean[1:(dim(dat.x6)[1]-(i-1))],method="kendall")}
plot(x6.cor.kendall,type="b")
abline(h=0,lty="dotted",col="grey")

x6.cor.spearman<-vector()
for (i in 1:8){
  x6.cor.spearman[i]<-cor(dat.x6$y.m.mean[i:dim(dat.x6)[1]],dat.x6$x6.m.mean[1:(dim(dat.x6)[1]-(i-1))],method="spearman")}
plot(x6.cor.spearman,type="b")
abline(h=0,lty="dotted",col="grey")

# ??��?? ?м??Ͻ? ?????? Ȱ?? ???Ŀ? ?ٰ??ϸ?, 
# y?? same row = lag 1: 2???? PTA??��?? 3???? spread?? ????
# 2???? ????��?? ?��? ?? ?? ??��
```

*X6 different weight for different future product*   
for each month, compare the correlation between each future price & spread  
```{r, message=FALSE, warning=FALSE, include=FALSE}
## x6: pta future-price fluctuation
names(dat.day)[which(names(dat.day)=="PTA Future Price_Jan_RMB")]<-"PTAFuture1"
names(dat.day)[which(names(dat.day)=="PTA Future Price_May_RMB")]<-"PTAFuture5"
names(dat.day)[which(names(dat.day)=="PTA Future Price_Sep_RMB")]<-"PTAFuture9"

# daily
test17<-na.omit(data.frame(dat.day$year,dat.day$month,dat.day$day,dat.day$PTAFuture1-dat.day$RMBPTA)) # delete NA row
test17<-test17[order(test17[,1],test17[,2],test17[,3]),] # check whether test17 is ordered by year, month, day since we assume that previous row = previous day @ next step
names(test17)[4]<-"PTA1diff"
test17$previous.PTA1diff[2:dim(test17)[1]]<-test17$PTA1diff[1:(dim(test17)[1]-1)] # add previous day column
dat.day<-merge(dat.day,test17,by.x=c("year","month","day"),by.y=c("dat.day.year","dat.day.month","dat.day.day"),all.x=TRUE) # merge diff & previous day columns next to today's PTAFuture, RMBPTA
dat.day$x6.f1.d<-dat.day$PTA1diff-dat.day$previous.PTA1diff # subtract today - previous day
  # fluctuation of daily difference of PTA1future & RMBPTA

# mean  

# start with adding monthly PTAFuture & RMBPTA = ptafuture.w.mean & ptarmb.w.mean @ dat.month data frame
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,ptafuture1.m.mean=mean(PTAFuture1,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)  
# we already have ptarmb.m.mean
# add ptafuture1.m.mean-ptarmb.m.mean = PTA1diff.mean @ data.month
test18<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$ptafuture1.m.mean-dat.month$ptarmb.m.mean)) # delete NA row
names(test18)[3]<-"PTA1diff.mean"
test18<-test18[order(test18[,1],test18[,2],test18[,3]),] # check whether test18 is ordered by year, month since we assume that previous row = previous month @ next step
test18$previous.PTA1diff.mean[2:dim(test18)[1]]<-test18$PTA1diff[1:(dim(test18)[1]-1)] # add previous month column
dat.month<-merge(dat.month,test18,by.x=c("year","month"),by.y=c("dat.month.year","dat.month.month"),all.x=TRUE) # merge diff & previous month column next to this month's PTAFuture, RMBPTA
dat.month$x6.f1.m<-dat.month$PTA1diff.mean-dat.month$previous.PTA1diff.mean # subtract this month - previous month
  # fluctuation of (monthly mean of pta future - monthly mean of pta rmb) (not same as the fluctuation of '30 days' mean of (pta future - pta rmb)')

# daily
test19<-na.omit(data.frame(dat.day$year,dat.day$month,dat.day$day,dat.day$PTAFuture5-dat.day$RMBPTA)) # delete NA row
test19<-test19[order(test19[,1],test19[,2],test19[,3]),] # check whether test19 is ordered by year, month, day since we assume that previous row = previous day @ next step
names(test19)[4]<-"PTA5diff"
test19$previous.PTA5diff[2:dim(test19)[1]]<-test19$PTA5diff[1:(dim(test19)[1]-1)] # add previous day column
dat.day<-merge(dat.day,test19,by.x=c("year","month","day"),by.y=c("dat.day.year","dat.day.month","dat.day.day"),all.x=TRUE) # merge diff & previous day columns next to today's PTAFuture, RMBPTA
dat.day$x6.f5.d<-dat.day$PTA5diff-dat.day$previous.PTA5diff # subtract today - previous day
  # fluctuation of daily difference of PTA1future & RMBPTA

# mean  

# start with adding monthly PTAFuture & RMBPTA = ptafuture.w.mean & ptarmb.w.mean @ dat.month data frame
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,ptafuture5.m.mean=mean(PTAFuture5,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)  
# we already have ptarmb.m.mean
# add ptafuture5.m.mean-ptarmb.m.mean = PTA5diff.mean @ data.month
test20<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$ptafuture5.m.mean-dat.month$ptarmb.m.mean)) # delete NA row
names(test20)[3]<-"PTA5diff.mean"
test20<-test20[order(test20[,1],test20[,2],test20[,3]),] # check whether test20 is ordered by year, month since we assume that previous row = previous month @ next step
test20$previous.PTA5diff.mean[2:dim(test20)[1]]<-test20$PTA5diff[1:(dim(test20)[1]-1)] # add previous month column
dat.month<-merge(dat.month,test20,by.x=c("year","month"),by.y=c("dat.month.year","dat.month.month"),all.x=TRUE) # merge diff & previous month column next to this month's PTAFuture, RMBPTA
dat.month$x6.f5.m<-dat.month$PTA5diff.mean-dat.month$previous.PTA5diff.mean # subtract this month - previous month
  # fluctuation of (monthly mean of pta future - monthly mean of pta rmb) (not same as the fluctuation of '30 days' mean of (pta future - pta rmb)')

# daily
test21<-na.omit(data.frame(dat.day$year,dat.day$month,dat.day$day,dat.day$PTAFuture9-dat.day$RMBPTA)) # delete NA row
test21<-test21[order(test21[,1],test21[,2],test21[,3]),] # check whether test21 is ordered by year, month, day since we assume that previous row = previous day @ next step
names(test21)[4]<-"PTA9diff"
test21$previous.PTA9diff[2:dim(test21)[1]]<-test21$PTA9diff[1:(dim(test21)[1]-1)] # add previous day column
dat.day<-merge(dat.day,test21,by.x=c("year","month","day"),by.y=c("dat.day.year","dat.day.month","dat.day.day"),all.x=TRUE) # merge diff & previous day columns next to today's PTAFuture, RMBPTA
dat.day$x6.f9.d<-dat.day$PTA9diff-dat.day$previous.PTA9diff # subtract today - previous day
  # fluctuation of daily difference of PTA1future & RMBPTA

# mean  

# start with adding monthly PTAFuture & RMBPTA = ptafuture.w.mean & ptarmb.w.mean @ dat.month data frame
dat.month<-merge(dat.month,ddply(dat.day,c("year","month"),summarize,ptafuture9.m.mean=mean(PTAFuture9,na.rm=TRUE)),by=c("year","month"),all.x=TRUE)  
# we already have ptarmb.m.mean
# add ptafuture9.m.mean-ptarmb.m.mean = PTA9diff.mean @ data.month
test22<-na.omit(data.frame(dat.month$year,dat.month$month,dat.month$ptafuture9.m.mean-dat.month$ptarmb.m.mean)) # delete NA row
names(test22)[3]<-"PTA9diff.mean"
test22<-test22[order(test22[,1],test22[,2],test22[,3]),] # check whether test22 is ordered by year, month since we assume that previous row = previous month @ next step
test22$previous.PTA9diff.mean[2:dim(test22)[1]]<-test22$PTA9diff[1:(dim(test22)[1]-1)] # add previous month column
dat.month<-merge(dat.month,test22,by.x=c("year","month"),by.y=c("dat.month.year","dat.month.month"),all.x=TRUE) # merge diff & previous month column next to this month's PTAFuture, RMBPTA
dat.month$x6.f9.m<-dat.month$PTA9diff.mean-dat.month$previous.PTA9diff.mean # subtract this month - previous month
  # fluctuation of (monthly mean of pta future - monthly mean of pta rmb) (not same as the fluctuation of '30 days' mean of (pta future - pta rmb)')

## now, we have 
## dat.month> x6.f1.d, x6.f1.m, x6.f5.d, x6.f5.m, x6.f9.d, x6.f9.m
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
## dat.day 30?? ????��?? ?ٿ??? ?ٽ? ?????غ? ??
future.pearson<-matrix(NA,nrow=12,ncol=3,dimnames=list(c(1:12),c("future1","future5","future9")))
for (i in 1:12){
test<-subset(dat.day,month%in%i,select=c(year,month,day,x6.f1.d,x6.f5.d,x6.f9.d,y.d))
future.pearson[i,]<-c(cor(test[,4],test[,7],use="pairwise.complete.obs",method="pearson"),cor(test[,5],test[,7],use="pairwise.complete.obs",method="pearson"),cor(test[,6],test[,7],use="pairwise.complete.obs",method="pearson"))}
future.pearson
```

based on my best guess, worse result for any combinations  
```{r, message=FALSE, warning=FALSE, include=FALSE}
# y = y.m.mean, x1 = y.m.mean (????+??????), x2 = pro.demand (????+??????+????????), x3 = x3.m (??????+????????), x5 = x5.m.mean (????), x6 = x6.m.mean (??????, 2015 ???? NA)
dat.guess<-subset(dat.month,year%in%c(2014:2016),select=c(Date,year,month,y.m.mean,previous.y.m.mean,twoago.y.m.mean,previous.pro.demand,twoago.pro.demand,threeago.pro.demand,twoago.x3.m,threeago.x3.m,previous.x5.m.mean,twoago.x6.m.mean))
dat.guess<-dat.guess[1:34,] # delete incomplete row at the end 2016.11-12
dat.guess$sum.y.m.mean<-dat.guess$previous.y.m.mean+dat.guess$twoago.y.m.mean # sum x1
dat.guess$sum.pro.demand<-dat.guess$previous.pro.demand+dat.guess$twoago.pro.demand+dat.guess$threeago.pro.demand # sum x2
dat.guess$sum.x3.m<-dat.guess$twoago.x3.m+dat.guess$threeago.x3.m # sum x3
dat.guess$twoago.x6.m.mean[1:12]<-mean(dat.guess$twoago.x6.m.mean[13:34])  # 2015 future data as mean
lm_new<-lm(y.m.mean~sum.y.m.mean+sum.pro.demand+sum.x3.m+previous.x5.m.mean+twoago.x6.m.mean,data=dat.guess)
summary(lm_new) # new model
```

try: original range + use my guess as additive  
change x1 only ~ x6 only, change 2 combinations ~ change all 6 variables  
-> changing x2, x6 seems reasonable  
adjusting range within x2, x6, x2 for five years & x6 for two years model showed best MSE
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# y = y.m.mean, x1 = y.m.mean (????), x2 = pro.demand (????+????+??????+????????), x3 = x3.m (????+??????), x4 = x4.m.mean, x5 = x5.m.mean (????), x6 = x6.m.mean (????+??????, 2015 ???? NA)
dat.new<-subset(dat.month,year%in%c(2014:2016),select=c(Date,year,month,y.m.mean,previous.y.m.mean,pro.demand,previous.pro.demand,twoago.pro.demand,threeago.pro.demand,fourago.pro.demand,fiveago.pro.demand,previous.x3.m,twoago.x3.m,x4.m.mean,previous.x5.m.mean,previous.x6.m.mean,twoago.x6.m.mean,threeago.x6.m.mean,fourago.x6.m.mean))
dat.new<-dat.new[1:34,] # delete incomplete row at the end 2016.11-12
dat.new$twosum.x3.m<-dat.new$previous.x3.m+dat.new$twoago.x3.m # sum expansion

##### adjust x2 & x6 sum part for model comparison - chose the best model based on adjusted r square & residual standard error

dat.new$sum.pro.demand<-dat.new$pro.demand+dat.new$previous.pro.demand+dat.new$twoago.pro.demand+dat.new$threeago.pro.demand+dat.new$fourago.pro.demand # sum x2
dat.new$sum.x6.m.mean<-dat.new$previous.x6.m.mean+dat.new$twoago.x6.m.mean # sum x6
dat.new$sum.x6.m.mean[1:12]<-mean(dat.new$sum.x6.m.mean[13:34])  # 2015 future data as mean

lm_new<-lm(y.m.mean~previous.y.m.mean+sum.pro.demand+twosum.x3.m+x4.m.mean+previous.x5.m.mean+sum.x6.m.mean,data=dat.new)
summary(step(lm_new)) # new model

lm_new.df<-(data.frame(dat.new$y.m.mean,dat.new$previous.y.m.mean,dat.new$sum.pro.demand,dat.new$twosum.x3.m,dat.new$x4.m.mean,dat.new$previous.x5.m.mean,dat.new$sum.x6.m.mean))
```

assumption check for the selected model  
(1) Linearity, Normality, homogeneity -ok
```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot(lm_new$residuals)
shapiro.test(lm_new$residuals)
ncvTest(lm_new)
# ???? ?׷??��? Ư???? ???? ?????? ?ʰ?, 
# ��??, ???л? ??��?? ??�� ???? ??��
# (null: normal/constant error variance)
```

(2) Multicolinearity -ok  
```{r, echo=FALSE, message=FALSE, warning=FALSE}
# (The definition of ??high?? is somewhat arbitrary but values in the range of 5-10 are commonly used.)
vif(lm_new)
```

(3) Independence -ok


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# (dw test null: errrors are uncorrelated)
acf(lm_new$residuals)
durbinWatsonTest(lm_new)# for autocorrelated error AR(1)
```

validate the model
```{r, message=FALSE, warning=FALSE, include=FALSE}
##### validate model
predict.adjusted<-data.frame(predict=NA,real=NA,lw.95ci=NA,up.95ci=NA,o.predict=predict.original[,1],o.lw.95ci=predict.original[,3],o.up.95ci=predict.original[,4])
for (i in 1:10){
lm<-step(lm(y.m.mean~previous.y.m.mean+sum.pro.demand+twosum.x3.m+x4.m.mean+previous.x5.m.mean+sum.x6.m.mean,data=dat.new[1:(23+i),]))
predict.adjusted[i,1]<-predict.lm(lm,dat.new[24+i,],interval="predict",level=0.95)[,1]
predict.adjusted[i,2]<-dat.new[24+i,4]
predict.adjusted[i,3]<-predict(lm,dat.new[24+i,],interval="predict",level=0.95)[,2]
predict.adjusted[i,4]<-predict(lm,dat.new[24+i,],interval="predict",level=0.95)[,3]
  }
cverror.adjusted<-sqrt(sum((predict.adjusted[,1]-predict.adjusted[,2])^2)/10)
```
mean of MSE from 2016.01-2016.10
```{r, echo=FALSE, message=FALSE, warning=FALSE}
predict.adjusted
cverror.adjusted
```
just for model comparison


```{r, echo=FALSE, message=FALSE, warning=FALSE}
matplot(predict.adjusted,type=c("p","b","p","p","p","p","p"),pch=c(8,20,18,18,8,18,18),col=c("red","black","red","red","grey","grey","grey"),ylim=c(250,500))
legend(x=6.5,y=350,c("real value","adjusted linear prediction","adjusted linear pi","linear prediction","linear pi"),col=c("black","red","red","grey","grey"),pch=c(20,8,18,8,18))
text(x=4.5,y=500,"cv error of original regression=22.21, after adjustment=15.28")
text(x=3.0,y=480,"one step prediction using previous data")
```

MSE plot comparison
predict.adjusted<-data.frame(predict=NA,real=NA,lw.95ci=NA,up.95ci=NA,o.predict=predict.original[,1],o.lw.95ci=predict.original[,3],o.up.95ci=predict.original[,4])
```{r, echo=FALSE, message=FALSE, warning=FALSE}
mse.comparison<-cbind(lm_new.df$dat.new.y.m.mean,predict.lm(lm_new,interval="confidence"),predict.lm(lm_original,interval="confidence"))
matplot(mse.comparison,type=c("b","p","p","p","p","p","p"),pch=c(20,8,18,18,8,18,18),col=c("black","red","red","red","grey","grey","grey"),ylim=c(250,500))
legend(x=25,y=350,c("real value","adjusted linear","adjusted linear ci","linear prediction","linear ci"),col=c("black","red","red","grey","grey"),pch=c(20,8,18,8,18))
text(x=13,y=500,"MSE of original regression=20.19, after adjustment=16.01")
```

residuals: adjusted vs. original  
@ 16/34 points, residuals from new medel are lower than those from original one  
original model performs worse in 2016
```{r, echo=FALSE, message=FALSE, warning=FALSE}
  matplot(data.frame(abs(mse.comparison[,2]-mse.comparison[,1]),abs(mse.comparison[,5]-mse.comparison[,1])),main="Real-Fitted value",type=c("b","b"),pch=c(20,8),col=c("black","grey"))
  legend(x=1,y=480,c("cumulative sum of residuals - adjusted model","cumulative sum of residuals - original model"),col=c("black","grey"),pch=c(20,8))
```

Cumulative sum of residuals: adjusted vs. original
```{r, echo=FALSE, message=FALSE, warning=FALSE}
  ressum.new<-cumsum(abs(mse.comparison[,2]-mse.comparison[,1]))
  ressum.org<-cumsum(abs(mse.comparison[,5]-mse.comparison[,1]))
  matplot(data.frame(ressum.new,ressum.org),main="Real-Fitted value",type=c("b","b"),pch=c(20,8),col=c("black","grey"))
  legend(x=1,y=480,c("cumulative sum of residuals - adjusted model","cumulative sum of residuals - original model"),col=c("black","grey"),pch=c(20,8))
```


fit model on 2014-2015 data, test model on 2016
```{r, message=FALSE, warning=FALSE, include=FALSE}
dat.new_train<-subset(dat.new,year%in%c(2014,2015))
dat.new_test<-subset(dat.new,year%in%2016)
lm_new_train<-lm(y.m.mean~previous.y.m.mean+sum.pro.demand+twosum.x3.m+x4.m.mean+previous.x5.m.mean+sum.x6.m.mean,data=dat.new_train)
summary(step(lm_new_train)) # new model


dat.org_train<-subset(dat.original,year%in%c(2014,2015))
dat.org_test<-subset(dat.original,year%in%2016)
lm_org_train<-lm(y.m.mean~previous.y.m.mean+pro.demand+twosum.x3.m+x4.m.mean+previous.x5.m.mean+previous.x6.m.mean,data=dat.original)
summary(step(lm_org_train))

testmse.comparison<-cbind(lm_new.df$dat.new.y.m.mean[25:34],predict.lm(lm_new_train,dat.new_test,interval="prediction"),predict.lm(lm_org_train,dat.new_test,interval="prediction"))

sqrt(sum((testmse.comparison[,2]-testmse.comparison[,1])^2)/10)
sqrt(sum((testmse.comparison[,5]-testmse.comparison[,1])^2)/10)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
matplot(testmse.comparison,type=c("b","p","p","p","p","p","p"),pch=c(20,8,18,18,8,18,18),col=c("black","red","red","red","grey","grey","grey"),ylim=c(300,500),main="Test error - test on 2016.01-2016.10 data")
legend(x=25,y=350,c("real value","adjusted linear","adjusted linear pi","linear prediction","linear pi"),col=c("black","red","red","grey","grey"),pch=c(20,8,18,8,18))
text(x=4.5,y=490,"test MSE of original regression=19.24, after adjustment=15.31")
```

residuals: adjusted vs. original  
@ 7/10 points, residuals from new medel are lower than those from original one
```{r, echo=FALSE, message=FALSE, warning=FALSE}
 matplot(data.frame(abs(testmse.comparison[,2]-testmse.comparison[,1]),abs(testmse.comparison[,5]-testmse.comparison[,1])),main="Real-Fitted value: test data",type=c("b","b"),pch=c(20,8),col=c("black","grey"))
  legend(x=1,y=480,c("cumulative sum of residuals - adjusted model","cumulative sum of residuals - original model"),col=c("black","grey"),pch=c(20,8))
```

Cumulative sum of residuals: adjusted vs. original
```{r, echo=FALSE, message=FALSE, warning=FALSE}
  test.ressum.new<-cumsum(abs(testmse.comparison[,2]-testmse.comparison[,1]))
  test.ressum.org<-cumsum(abs(testmse.comparison[,5]-testmse.comparison[,1]))
  matplot(data.frame(test.ressum.new,test.ressum.org),main="Real-Fitted value: test data",type=c("b","b"),pch=c(20,8),col=c("black","grey"))
  legend(x=1,y=480,c("cumulative sum of residuals - adjusted model","cumulative sum of residuals - original model"),col=c("black","grey"),pch=c(20,8))
```


